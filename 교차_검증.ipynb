{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "교차 검증",
      "provenance": [],
      "authorship_tag": "ABX9TyMTYz8Kz5mL1qgG2XWg3+2+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/repairedserver/Test/blob/master/%EA%B5%90%EC%B0%A8_%EA%B2%80%EC%A6%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbkgtibsPlwE",
        "outputId": "5290607c-d326-4fd5-bd03-359d65a81245"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd/content/gdrive/My Drive/deeplearningbro/deeplearningbro/pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dV-p7hGPqll",
        "outputId": "f937d42c-90f9-4b7c-f00e-be76919e4b61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/deeplearningbro/deeplearningbro/pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #데이터프레임\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#ANN\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#Loss\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#Plot\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "fs7L8vH4P69q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./data/reg.csv', index_col=[0])"
      ],
      "metadata": {
        "id": "GXspYYJuQkLq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Price', axis=1).to_numpy() #타겟값 제외 넘파이 배열\n",
        "Y = df['Price'].to_numpy().reshape((-1, 1))"
      ],
      "metadata": {
        "id": "5zrX1Z_sRN4t"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TensorData(Dataset):\n",
        "  def __init__(self, x_data, y_data):\n",
        "    self.x_data = torch.FloatTensor(x_data)\n",
        "    self.y_data = torch.FloatTensor(y_data)\n",
        "    self.len = self.y_data.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x_data[index], self.y_data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len"
      ],
      "metadata": {
        "id": "QiF-dx2iRjRs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.7)\n",
        "trainset = TensorData(X_train, Y_train)\n",
        "testset = TensorData(X_test, Y_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "I-EZA8R0RyHu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Regressor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__() #모델 연산 정의\n",
        "    self.fc1 = nn.Linear(13, 50, bias=True)\n",
        "    self.fc2 = nn.Linear(50, 30, bias=True)\n",
        "    self.fc3 = nn.Linear(30, 1, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "TSDvRmRBSyvF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KFold = KFold(n_splits=3, shuffle=True)"
      ],
      "metadata": {
        "id": "peI2mxW_TWdn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "tS5HAuY3TuDq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(dataloader):\n",
        "  predictions = torch.tensor([], dtype=torch.float)\n",
        "  actual = torch.tensor([], dtype=torch.float)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval() #평가시 .eval() 반드시 사용\n",
        "    for data in dataloader:\n",
        "      inputs, values = data\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      predictions = torch.cat((predictions, outputs), 0)\n",
        "      actual = torch.cat((actual, values), 0)\n",
        "\n",
        "    predictions = predictions.numpy()\n",
        "    actual = actual.numpy()\n",
        "    rmse = np.sqrt(mean_squared_error(predictions, actual))\n",
        "    model.train()\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "0Ym6b3zpTwkf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loss = []\n",
        "for fold, (train_idx, val_idx) in enumerate(KFold.split(trainset)):\n",
        "  train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "  val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "  #sampler를 이용한 DataLoader 정의\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, sampler=train_subsampler)\n",
        "  valloader = torch.utils.data.DataLoader(trainset, batch_size=32, sampler=val_subsampler)\n",
        "\n",
        "  model = Regressor()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-7)\n",
        "\n",
        "  for epoch in range(400):\n",
        "    for data in trainloader: #무작위로 섞인 32개 데이터가 있는 배치가 하나씩\n",
        "      inputs, values = data\n",
        "      optimizer.zero_grad() #최적화 초기화\n",
        "\n",
        "      outputs = model(inputs) #모델에 입력값 대입후 예측값\n",
        "      loss = criterion(outputs, values) #손실\n",
        "      loss.backward() #손실함수 기준으로 역전파\n",
        "      optimizer.step() #역전파 진행후 가중치\n",
        "\n",
        "    train_rmse = evaluation(trainloader) #학습 데이터의 RMSE\n",
        "    val_rmse = evaluation(valloader)\n",
        "    print(\"k-fold\", fold,\"Train Loss = %.4f, Validation Loss = %.4f\" %(train_rmse, val_rmse))\n",
        "    validation_loss.append(val_rmse)\n",
        "\n",
        "validation_loss = np.array(validation_loss)\n",
        "mean = np.mean(validation_loss)\n",
        "std = np.std(validation_loss)\n",
        "print(\"Validation Score: %.4f, +-%.4f\" %(mean, std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfCMMNjjUv3d",
        "outputId": "a2812b8e-ed3f-44b6-884e-4f014b722868"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-fold 0 Train Loss = 0.2893, Validation Loss = 0.2783\n",
            "k-fold 0 Train Loss = 0.2370, Validation Loss = 0.2603\n",
            "k-fold 0 Train Loss = 0.1763, Validation Loss = 0.1723\n",
            "k-fold 0 Train Loss = 0.1484, Validation Loss = 0.1528\n",
            "k-fold 0 Train Loss = 0.1707, Validation Loss = 0.1824\n",
            "k-fold 0 Train Loss = 0.1323, Validation Loss = 0.1418\n",
            "k-fold 0 Train Loss = 0.1372, Validation Loss = 0.1439\n",
            "k-fold 0 Train Loss = 0.1282, Validation Loss = 0.1415\n",
            "k-fold 0 Train Loss = 0.1291, Validation Loss = 0.1393\n",
            "k-fold 0 Train Loss = 0.1274, Validation Loss = 0.1358\n",
            "k-fold 0 Train Loss = 0.1175, Validation Loss = 0.1289\n",
            "k-fold 0 Train Loss = 0.1261, Validation Loss = 0.1374\n",
            "k-fold 0 Train Loss = 0.1179, Validation Loss = 0.1252\n",
            "k-fold 0 Train Loss = 0.1147, Validation Loss = 0.1222\n",
            "k-fold 0 Train Loss = 0.1127, Validation Loss = 0.1201\n",
            "k-fold 0 Train Loss = 0.1089, Validation Loss = 0.1172\n",
            "k-fold 0 Train Loss = 0.1234, Validation Loss = 0.1330\n",
            "k-fold 0 Train Loss = 0.1165, Validation Loss = 0.1273\n",
            "k-fold 0 Train Loss = 0.1079, Validation Loss = 0.1202\n",
            "k-fold 0 Train Loss = 0.1090, Validation Loss = 0.1216\n",
            "k-fold 0 Train Loss = 0.1086, Validation Loss = 0.1195\n",
            "k-fold 0 Train Loss = 0.1191, Validation Loss = 0.1309\n",
            "k-fold 0 Train Loss = 0.1086, Validation Loss = 0.1213\n",
            "k-fold 0 Train Loss = 0.1063, Validation Loss = 0.1197\n",
            "k-fold 0 Train Loss = 0.1058, Validation Loss = 0.1200\n",
            "k-fold 0 Train Loss = 0.1054, Validation Loss = 0.1202\n",
            "k-fold 0 Train Loss = 0.1044, Validation Loss = 0.1185\n",
            "k-fold 0 Train Loss = 0.1062, Validation Loss = 0.1187\n",
            "k-fold 0 Train Loss = 0.1078, Validation Loss = 0.1237\n",
            "k-fold 0 Train Loss = 0.1128, Validation Loss = 0.1242\n",
            "k-fold 0 Train Loss = 0.1066, Validation Loss = 0.1214\n",
            "k-fold 0 Train Loss = 0.1056, Validation Loss = 0.1172\n",
            "k-fold 0 Train Loss = 0.1079, Validation Loss = 0.1189\n",
            "k-fold 0 Train Loss = 0.1229, Validation Loss = 0.1304\n",
            "k-fold 0 Train Loss = 0.1201, Validation Loss = 0.1317\n",
            "k-fold 0 Train Loss = 0.1059, Validation Loss = 0.1191\n",
            "k-fold 0 Train Loss = 0.1617, Validation Loss = 0.1705\n",
            "k-fold 0 Train Loss = 0.1283, Validation Loss = 0.1436\n",
            "k-fold 0 Train Loss = 0.1146, Validation Loss = 0.1281\n",
            "k-fold 0 Train Loss = 0.1132, Validation Loss = 0.1255\n",
            "k-fold 0 Train Loss = 0.1088, Validation Loss = 0.1215\n",
            "k-fold 0 Train Loss = 0.1159, Validation Loss = 0.1272\n",
            "k-fold 0 Train Loss = 0.1207, Validation Loss = 0.1302\n",
            "k-fold 0 Train Loss = 0.1056, Validation Loss = 0.1157\n",
            "k-fold 0 Train Loss = 0.1057, Validation Loss = 0.1159\n",
            "k-fold 0 Train Loss = 0.1133, Validation Loss = 0.1237\n",
            "k-fold 0 Train Loss = 0.1128, Validation Loss = 0.1264\n",
            "k-fold 0 Train Loss = 0.1064, Validation Loss = 0.1212\n",
            "k-fold 0 Train Loss = 0.1050, Validation Loss = 0.1211\n",
            "k-fold 0 Train Loss = 0.1088, Validation Loss = 0.1267\n",
            "k-fold 0 Train Loss = 0.1045, Validation Loss = 0.1212\n",
            "k-fold 0 Train Loss = 0.1127, Validation Loss = 0.1243\n",
            "k-fold 0 Train Loss = 0.1162, Validation Loss = 0.1311\n",
            "k-fold 0 Train Loss = 0.1062, Validation Loss = 0.1189\n",
            "k-fold 0 Train Loss = 0.1047, Validation Loss = 0.1188\n",
            "k-fold 0 Train Loss = 0.1128, Validation Loss = 0.1284\n",
            "k-fold 0 Train Loss = 0.1177, Validation Loss = 0.1338\n",
            "k-fold 0 Train Loss = 0.1056, Validation Loss = 0.1231\n",
            "k-fold 0 Train Loss = 0.1069, Validation Loss = 0.1196\n",
            "k-fold 0 Train Loss = 0.1041, Validation Loss = 0.1198\n",
            "k-fold 0 Train Loss = 0.1047, Validation Loss = 0.1222\n",
            "k-fold 0 Train Loss = 0.1141, Validation Loss = 0.1269\n",
            "k-fold 0 Train Loss = 0.1038, Validation Loss = 0.1208\n",
            "k-fold 0 Train Loss = 0.1034, Validation Loss = 0.1196\n",
            "k-fold 0 Train Loss = 0.1045, Validation Loss = 0.1206\n",
            "k-fold 0 Train Loss = 0.1025, Validation Loss = 0.1191\n",
            "k-fold 0 Train Loss = 0.1056, Validation Loss = 0.1231\n",
            "k-fold 0 Train Loss = 0.1035, Validation Loss = 0.1188\n",
            "k-fold 0 Train Loss = 0.1055, Validation Loss = 0.1194\n",
            "k-fold 0 Train Loss = 0.1093, Validation Loss = 0.1244\n",
            "k-fold 0 Train Loss = 0.1060, Validation Loss = 0.1200\n",
            "k-fold 0 Train Loss = 0.1137, Validation Loss = 0.1239\n",
            "k-fold 0 Train Loss = 0.1079, Validation Loss = 0.1222\n",
            "k-fold 0 Train Loss = 0.1099, Validation Loss = 0.1238\n",
            "k-fold 0 Train Loss = 0.1046, Validation Loss = 0.1178\n",
            "k-fold 0 Train Loss = 0.1105, Validation Loss = 0.1232\n",
            "k-fold 0 Train Loss = 0.1135, Validation Loss = 0.1281\n",
            "k-fold 0 Train Loss = 0.1038, Validation Loss = 0.1186\n",
            "k-fold 0 Train Loss = 0.1053, Validation Loss = 0.1208\n",
            "k-fold 0 Train Loss = 0.1064, Validation Loss = 0.1207\n",
            "k-fold 0 Train Loss = 0.1037, Validation Loss = 0.1196\n",
            "k-fold 0 Train Loss = 0.1102, Validation Loss = 0.1257\n",
            "k-fold 0 Train Loss = 0.1090, Validation Loss = 0.1238\n",
            "k-fold 0 Train Loss = 0.1068, Validation Loss = 0.1209\n",
            "k-fold 0 Train Loss = 0.1207, Validation Loss = 0.1361\n",
            "k-fold 0 Train Loss = 0.1028, Validation Loss = 0.1162\n",
            "k-fold 0 Train Loss = 0.1233, Validation Loss = 0.1330\n",
            "k-fold 0 Train Loss = 0.1177, Validation Loss = 0.1340\n",
            "k-fold 0 Train Loss = 0.1028, Validation Loss = 0.1184\n",
            "k-fold 0 Train Loss = 0.1201, Validation Loss = 0.1298\n",
            "k-fold 0 Train Loss = 0.1166, Validation Loss = 0.1333\n",
            "k-fold 0 Train Loss = 0.1061, Validation Loss = 0.1176\n",
            "k-fold 0 Train Loss = 0.1288, Validation Loss = 0.1382\n",
            "k-fold 0 Train Loss = 0.1209, Validation Loss = 0.1338\n",
            "k-fold 0 Train Loss = 0.1053, Validation Loss = 0.1183\n",
            "k-fold 0 Train Loss = 0.1200, Validation Loss = 0.1305\n",
            "k-fold 0 Train Loss = 0.1038, Validation Loss = 0.1173\n",
            "k-fold 0 Train Loss = 0.1211, Validation Loss = 0.1356\n",
            "k-fold 0 Train Loss = 0.1266, Validation Loss = 0.1366\n",
            "k-fold 0 Train Loss = 0.1040, Validation Loss = 0.1188\n",
            "k-fold 0 Train Loss = 0.1095, Validation Loss = 0.1257\n",
            "k-fold 0 Train Loss = 0.1044, Validation Loss = 0.1178\n",
            "k-fold 0 Train Loss = 0.1040, Validation Loss = 0.1190\n",
            "k-fold 0 Train Loss = 0.1051, Validation Loss = 0.1206\n",
            "k-fold 0 Train Loss = 0.1075, Validation Loss = 0.1229\n",
            "k-fold 0 Train Loss = 0.1031, Validation Loss = 0.1207\n",
            "k-fold 0 Train Loss = 0.1036, Validation Loss = 0.1204\n",
            "k-fold 0 Train Loss = 0.1026, Validation Loss = 0.1205\n",
            "k-fold 0 Train Loss = 0.1028, Validation Loss = 0.1215\n",
            "k-fold 0 Train Loss = 0.1027, Validation Loss = 0.1207\n",
            "k-fold 0 Train Loss = 0.1145, Validation Loss = 0.1345\n",
            "k-fold 0 Train Loss = 0.1126, Validation Loss = 0.1275\n",
            "k-fold 0 Train Loss = 0.1063, Validation Loss = 0.1219\n",
            "k-fold 0 Train Loss = 0.1083, Validation Loss = 0.1258\n",
            "k-fold 0 Train Loss = 0.1086, Validation Loss = 0.1237\n",
            "k-fold 0 Train Loss = 0.1066, Validation Loss = 0.1221\n",
            "k-fold 0 Train Loss = 0.1045, Validation Loss = 0.1224\n",
            "k-fold 0 Train Loss = 0.1030, Validation Loss = 0.1202\n",
            "k-fold 0 Train Loss = 0.1024, Validation Loss = 0.1192\n",
            "k-fold 0 Train Loss = 0.1028, Validation Loss = 0.1208\n",
            "k-fold 0 Train Loss = 0.1031, Validation Loss = 0.1191\n",
            "k-fold 0 Train Loss = 0.1052, Validation Loss = 0.1187\n",
            "k-fold 0 Train Loss = 0.1021, Validation Loss = 0.1175\n",
            "k-fold 0 Train Loss = 0.1128, Validation Loss = 0.1305\n",
            "k-fold 0 Train Loss = 0.1047, Validation Loss = 0.1184\n",
            "k-fold 0 Train Loss = 0.1093, Validation Loss = 0.1268\n",
            "k-fold 0 Train Loss = 0.1052, Validation Loss = 0.1214\n",
            "k-fold 0 Train Loss = 0.1068, Validation Loss = 0.1221\n",
            "k-fold 0 Train Loss = 0.1027, Validation Loss = 0.1213\n",
            "k-fold 0 Train Loss = 0.1024, Validation Loss = 0.1210\n",
            "k-fold 0 Train Loss = 0.1032, Validation Loss = 0.1215\n",
            "k-fold 0 Train Loss = 0.1021, Validation Loss = 0.1209\n",
            "k-fold 0 Train Loss = 0.1030, Validation Loss = 0.1212\n",
            "k-fold 0 Train Loss = 0.1041, Validation Loss = 0.1218\n",
            "k-fold 0 Train Loss = 0.1031, Validation Loss = 0.1216\n",
            "k-fold 0 Train Loss = 0.1021, Validation Loss = 0.1207\n",
            "k-fold 0 Train Loss = 0.1021, Validation Loss = 0.1215\n",
            "k-fold 0 Train Loss = 0.1041, Validation Loss = 0.1221\n",
            "k-fold 0 Train Loss = 0.1138, Validation Loss = 0.1282\n",
            "k-fold 0 Train Loss = 0.1087, Validation Loss = 0.1299\n",
            "k-fold 0 Train Loss = 0.1049, Validation Loss = 0.1272\n",
            "k-fold 0 Train Loss = 0.1057, Validation Loss = 0.1246\n",
            "k-fold 0 Train Loss = 0.1034, Validation Loss = 0.1235\n",
            "k-fold 0 Train Loss = 0.1038, Validation Loss = 0.1267\n",
            "k-fold 0 Train Loss = 0.1012, Validation Loss = 0.1217\n",
            "k-fold 0 Train Loss = 0.1014, Validation Loss = 0.1222\n",
            "k-fold 0 Train Loss = 0.1071, Validation Loss = 0.1259\n",
            "k-fold 0 Train Loss = 0.1020, Validation Loss = 0.1220\n",
            "k-fold 0 Train Loss = 0.1038, Validation Loss = 0.1243\n",
            "k-fold 0 Train Loss = 0.1087, Validation Loss = 0.1251\n",
            "k-fold 0 Train Loss = 0.1035, Validation Loss = 0.1222\n",
            "k-fold 0 Train Loss = 0.1017, Validation Loss = 0.1202\n",
            "k-fold 0 Train Loss = 0.1076, Validation Loss = 0.1241\n",
            "k-fold 0 Train Loss = 0.1036, Validation Loss = 0.1236\n",
            "k-fold 0 Train Loss = 0.1047, Validation Loss = 0.1234\n",
            "k-fold 0 Train Loss = 0.1053, Validation Loss = 0.1224\n",
            "k-fold 0 Train Loss = 0.1041, Validation Loss = 0.1241\n",
            "k-fold 0 Train Loss = 0.1024, Validation Loss = 0.1216\n",
            "k-fold 0 Train Loss = 0.1035, Validation Loss = 0.1206\n",
            "k-fold 0 Train Loss = 0.1024, Validation Loss = 0.1202\n",
            "k-fold 0 Train Loss = 0.1046, Validation Loss = 0.1220\n",
            "k-fold 0 Train Loss = 0.1047, Validation Loss = 0.1223\n",
            "k-fold 0 Train Loss = 0.1050, Validation Loss = 0.1220\n",
            "k-fold 0 Train Loss = 0.1041, Validation Loss = 0.1223\n",
            "k-fold 0 Train Loss = 0.1051, Validation Loss = 0.1283\n",
            "k-fold 0 Train Loss = 0.1038, Validation Loss = 0.1230\n",
            "k-fold 0 Train Loss = 0.1027, Validation Loss = 0.1228\n",
            "k-fold 0 Train Loss = 0.1200, Validation Loss = 0.1448\n",
            "k-fold 0 Train Loss = 0.1034, Validation Loss = 0.1230\n",
            "k-fold 0 Train Loss = 0.1081, Validation Loss = 0.1248\n",
            "k-fold 0 Train Loss = 0.1049, Validation Loss = 0.1266\n",
            "k-fold 0 Train Loss = 0.1040, Validation Loss = 0.1217\n",
            "k-fold 0 Train Loss = 0.1024, Validation Loss = 0.1209\n",
            "k-fold 0 Train Loss = 0.1056, Validation Loss = 0.1250\n",
            "k-fold 0 Train Loss = 0.1073, Validation Loss = 0.1234\n",
            "k-fold 0 Train Loss = 0.1030, Validation Loss = 0.1212\n",
            "k-fold 0 Train Loss = 0.1073, Validation Loss = 0.1266\n",
            "k-fold 0 Train Loss = 0.1149, Validation Loss = 0.1296\n",
            "k-fold 0 Train Loss = 0.1029, Validation Loss = 0.1226\n",
            "k-fold 0 Train Loss = 0.1035, Validation Loss = 0.1239\n",
            "k-fold 0 Train Loss = 0.1027, Validation Loss = 0.1236\n",
            "k-fold 0 Train Loss = 0.1036, Validation Loss = 0.1231\n",
            "k-fold 0 Train Loss = 0.1027, Validation Loss = 0.1237\n",
            "k-fold 0 Train Loss = 0.1034, Validation Loss = 0.1263\n",
            "k-fold 0 Train Loss = 0.1063, Validation Loss = 0.1255\n",
            "k-fold 0 Train Loss = 0.1026, Validation Loss = 0.1245\n",
            "k-fold 0 Train Loss = 0.1037, Validation Loss = 0.1240\n",
            "k-fold 0 Train Loss = 0.1041, Validation Loss = 0.1238\n",
            "k-fold 0 Train Loss = 0.1094, Validation Loss = 0.1337\n",
            "k-fold 0 Train Loss = 0.1082, Validation Loss = 0.1305\n",
            "k-fold 0 Train Loss = 0.1098, Validation Loss = 0.1282\n",
            "k-fold 0 Train Loss = 0.1101, Validation Loss = 0.1322\n",
            "k-fold 0 Train Loss = 0.1283, Validation Loss = 0.1401\n",
            "k-fold 0 Train Loss = 0.1069, Validation Loss = 0.1225\n",
            "k-fold 0 Train Loss = 0.1088, Validation Loss = 0.1245\n",
            "k-fold 0 Train Loss = 0.1090, Validation Loss = 0.1230\n",
            "k-fold 0 Train Loss = 0.1097, Validation Loss = 0.1241\n",
            "k-fold 0 Train Loss = 0.1042, Validation Loss = 0.1188\n",
            "k-fold 0 Train Loss = 0.1039, Validation Loss = 0.1209\n",
            "k-fold 0 Train Loss = 0.1125, Validation Loss = 0.1310\n",
            "k-fold 0 Train Loss = 0.1176, Validation Loss = 0.1294\n",
            "k-fold 0 Train Loss = 0.1029, Validation Loss = 0.1191\n",
            "k-fold 0 Train Loss = 0.1115, Validation Loss = 0.1293\n",
            "k-fold 0 Train Loss = 0.1217, Validation Loss = 0.1345\n",
            "k-fold 0 Train Loss = 0.1061, Validation Loss = 0.1208\n",
            "k-fold 0 Train Loss = 0.1125, Validation Loss = 0.1280\n",
            "k-fold 0 Train Loss = 0.1055, Validation Loss = 0.1213\n",
            "k-fold 0 Train Loss = 0.1067, Validation Loss = 0.1221\n",
            "k-fold 0 Train Loss = 0.1132, Validation Loss = 0.1302\n",
            "k-fold 0 Train Loss = 0.1107, Validation Loss = 0.1271\n",
            "k-fold 0 Train Loss = 0.1126, Validation Loss = 0.1258\n",
            "k-fold 0 Train Loss = 0.1114, Validation Loss = 0.1246\n",
            "k-fold 0 Train Loss = 0.1063, Validation Loss = 0.1225\n",
            "k-fold 0 Train Loss = 0.1018, Validation Loss = 0.1182\n",
            "k-fold 0 Train Loss = 0.1051, Validation Loss = 0.1206\n",
            "k-fold 0 Train Loss = 0.1041, Validation Loss = 0.1224\n",
            "k-fold 0 Train Loss = 0.1054, Validation Loss = 0.1255\n",
            "k-fold 0 Train Loss = 0.1074, Validation Loss = 0.1246\n",
            "k-fold 0 Train Loss = 0.1036, Validation Loss = 0.1223\n",
            "k-fold 0 Train Loss = 0.1156, Validation Loss = 0.1359\n",
            "k-fold 0 Train Loss = 0.1032, Validation Loss = 0.1219\n",
            "k-fold 0 Train Loss = 0.1141, Validation Loss = 0.1282\n",
            "k-fold 0 Train Loss = 0.1049, Validation Loss = 0.1210\n",
            "k-fold 0 Train Loss = 0.1078, Validation Loss = 0.1268\n",
            "k-fold 0 Train Loss = 0.1074, Validation Loss = 0.1252\n",
            "k-fold 0 Train Loss = 0.1093, Validation Loss = 0.1272\n",
            "k-fold 0 Train Loss = 0.1072, Validation Loss = 0.1272\n",
            "k-fold 0 Train Loss = 0.1050, Validation Loss = 0.1252\n",
            "k-fold 0 Train Loss = 0.1047, Validation Loss = 0.1252\n",
            "k-fold 0 Train Loss = 0.1044, Validation Loss = 0.1246\n",
            "k-fold 0 Train Loss = 0.1025, Validation Loss = 0.1214\n",
            "k-fold 0 Train Loss = 0.1056, Validation Loss = 0.1226\n",
            "k-fold 0 Train Loss = 0.1049, Validation Loss = 0.1228\n",
            "k-fold 0 Train Loss = 0.1025, Validation Loss = 0.1214\n",
            "k-fold 0 Train Loss = 0.1040, Validation Loss = 0.1214\n",
            "k-fold 0 Train Loss = 0.1028, Validation Loss = 0.1199\n",
            "k-fold 0 Train Loss = 0.1024, Validation Loss = 0.1192\n",
            "k-fold 0 Train Loss = 0.1040, Validation Loss = 0.1189\n",
            "k-fold 0 Train Loss = 0.1034, Validation Loss = 0.1185\n",
            "k-fold 0 Train Loss = 0.1023, Validation Loss = 0.1187\n",
            "k-fold 0 Train Loss = 0.1018, Validation Loss = 0.1191\n",
            "k-fold 0 Train Loss = 0.1024, Validation Loss = 0.1203\n",
            "k-fold 0 Train Loss = 0.1015, Validation Loss = 0.1208\n",
            "k-fold 0 Train Loss = 0.1016, Validation Loss = 0.1216\n",
            "k-fold 0 Train Loss = 0.1042, Validation Loss = 0.1221\n",
            "k-fold 0 Train Loss = 0.1041, Validation Loss = 0.1218\n",
            "k-fold 0 Train Loss = 0.1019, Validation Loss = 0.1213\n",
            "k-fold 0 Train Loss = 0.1014, Validation Loss = 0.1211\n",
            "k-fold 0 Train Loss = 0.1013, Validation Loss = 0.1213\n",
            "k-fold 0 Train Loss = 0.1017, Validation Loss = 0.1232\n",
            "k-fold 0 Train Loss = 0.1026, Validation Loss = 0.1222\n",
            "k-fold 0 Train Loss = 0.1036, Validation Loss = 0.1226\n",
            "k-fold 0 Train Loss = 0.1041, Validation Loss = 0.1229\n",
            "k-fold 0 Train Loss = 0.1026, Validation Loss = 0.1228\n",
            "k-fold 0 Train Loss = 0.1026, Validation Loss = 0.1238\n",
            "k-fold 0 Train Loss = 0.1067, Validation Loss = 0.1275\n",
            "k-fold 0 Train Loss = 0.1094, Validation Loss = 0.1259\n",
            "k-fold 0 Train Loss = 0.1017, Validation Loss = 0.1220\n",
            "k-fold 0 Train Loss = 0.1027, Validation Loss = 0.1219\n",
            "k-fold 0 Train Loss = 0.1050, Validation Loss = 0.1216\n",
            "k-fold 0 Train Loss = 0.1025, Validation Loss = 0.1202\n",
            "k-fold 0 Train Loss = 0.1029, Validation Loss = 0.1204\n",
            "k-fold 0 Train Loss = 0.1058, Validation Loss = 0.1234\n",
            "k-fold 0 Train Loss = 0.1021, Validation Loss = 0.1214\n",
            "k-fold 0 Train Loss = 0.1024, Validation Loss = 0.1213\n",
            "k-fold 0 Train Loss = 0.1042, Validation Loss = 0.1222\n",
            "k-fold 0 Train Loss = 0.1038, Validation Loss = 0.1224\n",
            "k-fold 0 Train Loss = 0.1025, Validation Loss = 0.1222\n",
            "k-fold 0 Train Loss = 0.1040, Validation Loss = 0.1233\n",
            "k-fold 0 Train Loss = 0.1022, Validation Loss = 0.1254\n",
            "k-fold 0 Train Loss = 0.1054, Validation Loss = 0.1298\n",
            "k-fold 0 Train Loss = 0.1044, Validation Loss = 0.1243\n",
            "k-fold 0 Train Loss = 0.1025, Validation Loss = 0.1259\n",
            "k-fold 0 Train Loss = 0.1019, Validation Loss = 0.1254\n",
            "k-fold 0 Train Loss = 0.1062, Validation Loss = 0.1254\n",
            "k-fold 0 Train Loss = 0.1032, Validation Loss = 0.1240\n",
            "k-fold 0 Train Loss = 0.1078, Validation Loss = 0.1304\n",
            "k-fold 0 Train Loss = 0.1057, Validation Loss = 0.1286\n",
            "k-fold 0 Train Loss = 0.1090, Validation Loss = 0.1285\n",
            "k-fold 0 Train Loss = 0.1025, Validation Loss = 0.1233\n",
            "k-fold 0 Train Loss = 0.1038, Validation Loss = 0.1223\n",
            "k-fold 0 Train Loss = 0.1036, Validation Loss = 0.1211\n",
            "k-fold 0 Train Loss = 0.1027, Validation Loss = 0.1203\n",
            "k-fold 0 Train Loss = 0.1023, Validation Loss = 0.1219\n",
            "k-fold 0 Train Loss = 0.1051, Validation Loss = 0.1267\n",
            "k-fold 0 Train Loss = 0.1037, Validation Loss = 0.1256\n",
            "k-fold 0 Train Loss = 0.1033, Validation Loss = 0.1258\n",
            "k-fold 0 Train Loss = 0.1064, Validation Loss = 0.1287\n",
            "k-fold 0 Train Loss = 0.1193, Validation Loss = 0.1335\n",
            "k-fold 0 Train Loss = 0.1054, Validation Loss = 0.1222\n",
            "k-fold 0 Train Loss = 0.1246, Validation Loss = 0.1412\n",
            "k-fold 0 Train Loss = 0.1111, Validation Loss = 0.1291\n",
            "k-fold 0 Train Loss = 0.1141, Validation Loss = 0.1280\n",
            "k-fold 0 Train Loss = 0.1027, Validation Loss = 0.1194\n",
            "k-fold 0 Train Loss = 0.1111, Validation Loss = 0.1283\n",
            "k-fold 0 Train Loss = 0.1134, Validation Loss = 0.1259\n",
            "k-fold 0 Train Loss = 0.1075, Validation Loss = 0.1213\n",
            "k-fold 0 Train Loss = 0.1117, Validation Loss = 0.1306\n",
            "k-fold 0 Train Loss = 0.1076, Validation Loss = 0.1229\n",
            "k-fold 0 Train Loss = 0.1183, Validation Loss = 0.1310\n",
            "k-fold 0 Train Loss = 0.1034, Validation Loss = 0.1209\n",
            "k-fold 0 Train Loss = 0.1069, Validation Loss = 0.1228\n",
            "k-fold 0 Train Loss = 0.1064, Validation Loss = 0.1222\n",
            "k-fold 0 Train Loss = 0.1020, Validation Loss = 0.1205\n",
            "k-fold 0 Train Loss = 0.1036, Validation Loss = 0.1232\n",
            "k-fold 0 Train Loss = 0.1059, Validation Loss = 0.1261\n",
            "k-fold 0 Train Loss = 0.1037, Validation Loss = 0.1229\n",
            "k-fold 0 Train Loss = 0.1046, Validation Loss = 0.1277\n",
            "k-fold 0 Train Loss = 0.1066, Validation Loss = 0.1287\n",
            "k-fold 0 Train Loss = 0.1108, Validation Loss = 0.1282\n",
            "k-fold 0 Train Loss = 0.1032, Validation Loss = 0.1250\n",
            "k-fold 0 Train Loss = 0.1097, Validation Loss = 0.1331\n",
            "k-fold 0 Train Loss = 0.1043, Validation Loss = 0.1235\n",
            "k-fold 0 Train Loss = 0.1056, Validation Loss = 0.1230\n",
            "k-fold 0 Train Loss = 0.1077, Validation Loss = 0.1270\n",
            "k-fold 0 Train Loss = 0.1047, Validation Loss = 0.1208\n",
            "k-fold 0 Train Loss = 0.1086, Validation Loss = 0.1237\n",
            "k-fold 0 Train Loss = 0.1054, Validation Loss = 0.1238\n",
            "k-fold 0 Train Loss = 0.1058, Validation Loss = 0.1277\n",
            "k-fold 0 Train Loss = 0.1215, Validation Loss = 0.1366\n",
            "k-fold 0 Train Loss = 0.1022, Validation Loss = 0.1211\n",
            "k-fold 0 Train Loss = 0.1035, Validation Loss = 0.1221\n",
            "k-fold 0 Train Loss = 0.1084, Validation Loss = 0.1244\n",
            "k-fold 0 Train Loss = 0.1045, Validation Loss = 0.1216\n",
            "k-fold 0 Train Loss = 0.1140, Validation Loss = 0.1341\n",
            "k-fold 0 Train Loss = 0.1040, Validation Loss = 0.1254\n",
            "k-fold 0 Train Loss = 0.1095, Validation Loss = 0.1270\n",
            "k-fold 0 Train Loss = 0.1022, Validation Loss = 0.1254\n",
            "k-fold 0 Train Loss = 0.1044, Validation Loss = 0.1283\n",
            "k-fold 0 Train Loss = 0.1059, Validation Loss = 0.1240\n",
            "k-fold 0 Train Loss = 0.1051, Validation Loss = 0.1239\n",
            "k-fold 0 Train Loss = 0.1081, Validation Loss = 0.1271\n",
            "k-fold 0 Train Loss = 0.1030, Validation Loss = 0.1213\n",
            "k-fold 0 Train Loss = 0.1173, Validation Loss = 0.1304\n",
            "k-fold 0 Train Loss = 0.1023, Validation Loss = 0.1207\n",
            "k-fold 0 Train Loss = 0.1166, Validation Loss = 0.1362\n",
            "k-fold 0 Train Loss = 0.1037, Validation Loss = 0.1210\n",
            "k-fold 0 Train Loss = 0.1088, Validation Loss = 0.1251\n",
            "k-fold 0 Train Loss = 0.1015, Validation Loss = 0.1223\n",
            "k-fold 0 Train Loss = 0.1020, Validation Loss = 0.1236\n",
            "k-fold 0 Train Loss = 0.1023, Validation Loss = 0.1228\n",
            "k-fold 0 Train Loss = 0.1067, Validation Loss = 0.1252\n",
            "k-fold 0 Train Loss = 0.1039, Validation Loss = 0.1236\n",
            "k-fold 0 Train Loss = 0.1050, Validation Loss = 0.1277\n",
            "k-fold 0 Train Loss = 0.1066, Validation Loss = 0.1306\n",
            "k-fold 0 Train Loss = 0.1037, Validation Loss = 0.1239\n",
            "k-fold 0 Train Loss = 0.1048, Validation Loss = 0.1251\n",
            "k-fold 0 Train Loss = 0.1080, Validation Loss = 0.1305\n",
            "k-fold 0 Train Loss = 0.1018, Validation Loss = 0.1221\n",
            "k-fold 0 Train Loss = 0.1033, Validation Loss = 0.1217\n",
            "k-fold 0 Train Loss = 0.1064, Validation Loss = 0.1238\n",
            "k-fold 0 Train Loss = 0.1060, Validation Loss = 0.1235\n",
            "k-fold 0 Train Loss = 0.1035, Validation Loss = 0.1210\n",
            "k-fold 0 Train Loss = 0.1028, Validation Loss = 0.1216\n",
            "k-fold 0 Train Loss = 0.1023, Validation Loss = 0.1213\n",
            "k-fold 0 Train Loss = 0.1065, Validation Loss = 0.1269\n",
            "k-fold 0 Train Loss = 0.1059, Validation Loss = 0.1245\n",
            "k-fold 0 Train Loss = 0.1065, Validation Loss = 0.1241\n",
            "k-fold 0 Train Loss = 0.1019, Validation Loss = 0.1227\n",
            "k-fold 0 Train Loss = 0.1197, Validation Loss = 0.1433\n",
            "k-fold 0 Train Loss = 0.1137, Validation Loss = 0.1309\n",
            "k-fold 0 Train Loss = 0.1019, Validation Loss = 0.1231\n",
            "k-fold 0 Train Loss = 0.1117, Validation Loss = 0.1336\n",
            "k-fold 0 Train Loss = 0.1025, Validation Loss = 0.1212\n",
            "k-fold 0 Train Loss = 0.1107, Validation Loss = 0.1267\n",
            "k-fold 0 Train Loss = 0.1040, Validation Loss = 0.1252\n",
            "k-fold 0 Train Loss = 0.1223, Validation Loss = 0.1449\n",
            "k-fold 0 Train Loss = 0.1038, Validation Loss = 0.1215\n",
            "k-fold 0 Train Loss = 0.1092, Validation Loss = 0.1246\n",
            "k-fold 0 Train Loss = 0.1027, Validation Loss = 0.1207\n",
            "k-fold 0 Train Loss = 0.1025, Validation Loss = 0.1208\n",
            "k-fold 0 Train Loss = 0.1014, Validation Loss = 0.1191\n",
            "k-fold 0 Train Loss = 0.1025, Validation Loss = 0.1194\n",
            "k-fold 0 Train Loss = 0.1026, Validation Loss = 0.1201\n",
            "k-fold 0 Train Loss = 0.1087, Validation Loss = 0.1250\n",
            "k-fold 0 Train Loss = 0.1044, Validation Loss = 0.1206\n",
            "k-fold 0 Train Loss = 0.1071, Validation Loss = 0.1230\n",
            "k-fold 0 Train Loss = 0.1024, Validation Loss = 0.1200\n",
            "k-fold 0 Train Loss = 0.1026, Validation Loss = 0.1214\n",
            "k-fold 0 Train Loss = 0.1025, Validation Loss = 0.1215\n",
            "k-fold 0 Train Loss = 0.1116, Validation Loss = 0.1319\n",
            "k-fold 0 Train Loss = 0.1054, Validation Loss = 0.1249\n",
            "k-fold 0 Train Loss = 0.1057, Validation Loss = 0.1220\n",
            "k-fold 0 Train Loss = 0.1161, Validation Loss = 0.1333\n",
            "k-fold 0 Train Loss = 0.1086, Validation Loss = 0.1264\n",
            "k-fold 0 Train Loss = 0.1104, Validation Loss = 0.1251\n",
            "k-fold 0 Train Loss = 0.1024, Validation Loss = 0.1211\n",
            "k-fold 0 Train Loss = 0.1035, Validation Loss = 0.1214\n",
            "k-fold 0 Train Loss = 0.1095, Validation Loss = 0.1255\n",
            "k-fold 0 Train Loss = 0.1131, Validation Loss = 0.1344\n",
            "k-fold 0 Train Loss = 0.1029, Validation Loss = 0.1237\n",
            "k-fold 0 Train Loss = 0.1014, Validation Loss = 0.1204\n",
            "k-fold 0 Train Loss = 0.1041, Validation Loss = 0.1210\n",
            "k-fold 0 Train Loss = 0.1021, Validation Loss = 0.1201\n",
            "k-fold 0 Train Loss = 0.1036, Validation Loss = 0.1224\n",
            "k-fold 0 Train Loss = 0.1037, Validation Loss = 0.1203\n",
            "k-fold 0 Train Loss = 0.1024, Validation Loss = 0.1195\n",
            "k-fold 0 Train Loss = 0.1030, Validation Loss = 0.1201\n",
            "k-fold 0 Train Loss = 0.1050, Validation Loss = 0.1215\n",
            "k-fold 0 Train Loss = 0.1038, Validation Loss = 0.1200\n",
            "k-fold 1 Train Loss = 0.2986, Validation Loss = 0.3038\n",
            "k-fold 1 Train Loss = 0.1519, Validation Loss = 0.1588\n",
            "k-fold 1 Train Loss = 0.1583, Validation Loss = 0.1651\n",
            "k-fold 1 Train Loss = 0.1708, Validation Loss = 0.1804\n",
            "k-fold 1 Train Loss = 0.1394, Validation Loss = 0.1511\n",
            "k-fold 1 Train Loss = 0.1482, Validation Loss = 0.1565\n",
            "k-fold 1 Train Loss = 0.1301, Validation Loss = 0.1421\n",
            "k-fold 1 Train Loss = 0.1399, Validation Loss = 0.1523\n",
            "k-fold 1 Train Loss = 0.1273, Validation Loss = 0.1389\n",
            "k-fold 1 Train Loss = 0.1296, Validation Loss = 0.1374\n",
            "k-fold 1 Train Loss = 0.1239, Validation Loss = 0.1329\n",
            "k-fold 1 Train Loss = 0.1267, Validation Loss = 0.1375\n",
            "k-fold 1 Train Loss = 0.1199, Validation Loss = 0.1303\n",
            "k-fold 1 Train Loss = 0.1223, Validation Loss = 0.1327\n",
            "k-fold 1 Train Loss = 0.1210, Validation Loss = 0.1315\n",
            "k-fold 1 Train Loss = 0.1149, Validation Loss = 0.1258\n",
            "k-fold 1 Train Loss = 0.1213, Validation Loss = 0.1303\n",
            "k-fold 1 Train Loss = 0.1155, Validation Loss = 0.1267\n",
            "k-fold 1 Train Loss = 0.1293, Validation Loss = 0.1391\n",
            "k-fold 1 Train Loss = 0.1157, Validation Loss = 0.1290\n",
            "k-fold 1 Train Loss = 0.1133, Validation Loss = 0.1271\n",
            "k-fold 1 Train Loss = 0.1135, Validation Loss = 0.1269\n",
            "k-fold 1 Train Loss = 0.1115, Validation Loss = 0.1246\n",
            "k-fold 1 Train Loss = 0.1148, Validation Loss = 0.1270\n",
            "k-fold 1 Train Loss = 0.1137, Validation Loss = 0.1250\n",
            "k-fold 1 Train Loss = 0.1107, Validation Loss = 0.1228\n",
            "k-fold 1 Train Loss = 0.1129, Validation Loss = 0.1241\n",
            "k-fold 1 Train Loss = 0.1206, Validation Loss = 0.1285\n",
            "k-fold 1 Train Loss = 0.1175, Validation Loss = 0.1281\n",
            "k-fold 1 Train Loss = 0.1094, Validation Loss = 0.1176\n",
            "k-fold 1 Train Loss = 0.1239, Validation Loss = 0.1274\n",
            "k-fold 1 Train Loss = 0.1293, Validation Loss = 0.1319\n",
            "k-fold 1 Train Loss = 0.1184, Validation Loss = 0.1290\n",
            "k-fold 1 Train Loss = 0.1292, Validation Loss = 0.1388\n",
            "k-fold 1 Train Loss = 0.1332, Validation Loss = 0.1430\n",
            "k-fold 1 Train Loss = 0.1146, Validation Loss = 0.1233\n",
            "k-fold 1 Train Loss = 0.1172, Validation Loss = 0.1237\n",
            "k-fold 1 Train Loss = 0.1120, Validation Loss = 0.1198\n",
            "k-fold 1 Train Loss = 0.1105, Validation Loss = 0.1190\n",
            "k-fold 1 Train Loss = 0.1096, Validation Loss = 0.1188\n",
            "k-fold 1 Train Loss = 0.1085, Validation Loss = 0.1168\n",
            "k-fold 1 Train Loss = 0.1126, Validation Loss = 0.1191\n",
            "k-fold 1 Train Loss = 0.1097, Validation Loss = 0.1162\n",
            "k-fold 1 Train Loss = 0.1084, Validation Loss = 0.1131\n",
            "k-fold 1 Train Loss = 0.1098, Validation Loss = 0.1141\n",
            "k-fold 1 Train Loss = 0.1190, Validation Loss = 0.1258\n",
            "k-fold 1 Train Loss = 0.1083, Validation Loss = 0.1134\n",
            "k-fold 1 Train Loss = 0.1229, Validation Loss = 0.1261\n",
            "k-fold 1 Train Loss = 0.1163, Validation Loss = 0.1230\n",
            "k-fold 1 Train Loss = 0.1103, Validation Loss = 0.1182\n",
            "k-fold 1 Train Loss = 0.1303, Validation Loss = 0.1345\n",
            "k-fold 1 Train Loss = 0.1150, Validation Loss = 0.1246\n",
            "k-fold 1 Train Loss = 0.1108, Validation Loss = 0.1187\n",
            "k-fold 1 Train Loss = 0.1556, Validation Loss = 0.1577\n",
            "k-fold 1 Train Loss = 0.1191, Validation Loss = 0.1270\n",
            "k-fold 1 Train Loss = 0.1271, Validation Loss = 0.1346\n",
            "k-fold 1 Train Loss = 0.1138, Validation Loss = 0.1191\n",
            "k-fold 1 Train Loss = 0.1125, Validation Loss = 0.1173\n",
            "k-fold 1 Train Loss = 0.1201, Validation Loss = 0.1242\n",
            "k-fold 1 Train Loss = 0.1125, Validation Loss = 0.1202\n",
            "k-fold 1 Train Loss = 0.1096, Validation Loss = 0.1175\n",
            "k-fold 1 Train Loss = 0.1123, Validation Loss = 0.1203\n",
            "k-fold 1 Train Loss = 0.1088, Validation Loss = 0.1161\n",
            "k-fold 1 Train Loss = 0.1154, Validation Loss = 0.1216\n",
            "k-fold 1 Train Loss = 0.1082, Validation Loss = 0.1156\n",
            "k-fold 1 Train Loss = 0.1075, Validation Loss = 0.1139\n",
            "k-fold 1 Train Loss = 0.1093, Validation Loss = 0.1155\n",
            "k-fold 1 Train Loss = 0.1268, Validation Loss = 0.1334\n",
            "k-fold 1 Train Loss = 0.1204, Validation Loss = 0.1303\n",
            "k-fold 1 Train Loss = 0.1108, Validation Loss = 0.1190\n",
            "k-fold 1 Train Loss = 0.1225, Validation Loss = 0.1301\n",
            "k-fold 1 Train Loss = 0.1112, Validation Loss = 0.1203\n",
            "k-fold 1 Train Loss = 0.1074, Validation Loss = 0.1172\n",
            "k-fold 1 Train Loss = 0.1123, Validation Loss = 0.1217\n",
            "k-fold 1 Train Loss = 0.1110, Validation Loss = 0.1210\n",
            "k-fold 1 Train Loss = 0.1098, Validation Loss = 0.1175\n",
            "k-fold 1 Train Loss = 0.1148, Validation Loss = 0.1209\n",
            "k-fold 1 Train Loss = 0.1087, Validation Loss = 0.1151\n",
            "k-fold 1 Train Loss = 0.1075, Validation Loss = 0.1132\n",
            "k-fold 1 Train Loss = 0.1119, Validation Loss = 0.1180\n",
            "k-fold 1 Train Loss = 0.1115, Validation Loss = 0.1174\n",
            "k-fold 1 Train Loss = 0.1145, Validation Loss = 0.1231\n",
            "k-fold 1 Train Loss = 0.1130, Validation Loss = 0.1210\n",
            "k-fold 1 Train Loss = 0.1104, Validation Loss = 0.1190\n",
            "k-fold 1 Train Loss = 0.1105, Validation Loss = 0.1196\n",
            "k-fold 1 Train Loss = 0.1132, Validation Loss = 0.1238\n",
            "k-fold 1 Train Loss = 0.1078, Validation Loss = 0.1179\n",
            "k-fold 1 Train Loss = 0.1116, Validation Loss = 0.1215\n",
            "k-fold 1 Train Loss = 0.1100, Validation Loss = 0.1193\n",
            "k-fold 1 Train Loss = 0.1107, Validation Loss = 0.1189\n",
            "k-fold 1 Train Loss = 0.1124, Validation Loss = 0.1214\n",
            "k-fold 1 Train Loss = 0.1077, Validation Loss = 0.1161\n",
            "k-fold 1 Train Loss = 0.1137, Validation Loss = 0.1203\n",
            "k-fold 1 Train Loss = 0.1067, Validation Loss = 0.1145\n",
            "k-fold 1 Train Loss = 0.1088, Validation Loss = 0.1163\n",
            "k-fold 1 Train Loss = 0.1136, Validation Loss = 0.1200\n",
            "k-fold 1 Train Loss = 0.1073, Validation Loss = 0.1135\n",
            "k-fold 1 Train Loss = 0.1114, Validation Loss = 0.1173\n",
            "k-fold 1 Train Loss = 0.1080, Validation Loss = 0.1140\n",
            "k-fold 1 Train Loss = 0.1075, Validation Loss = 0.1146\n",
            "k-fold 1 Train Loss = 0.1085, Validation Loss = 0.1175\n",
            "k-fold 1 Train Loss = 0.1098, Validation Loss = 0.1214\n",
            "k-fold 1 Train Loss = 0.1076, Validation Loss = 0.1189\n",
            "k-fold 1 Train Loss = 0.1100, Validation Loss = 0.1196\n",
            "k-fold 1 Train Loss = 0.1069, Validation Loss = 0.1164\n",
            "k-fold 1 Train Loss = 0.1098, Validation Loss = 0.1185\n",
            "k-fold 1 Train Loss = 0.1072, Validation Loss = 0.1161\n",
            "k-fold 1 Train Loss = 0.1072, Validation Loss = 0.1163\n",
            "k-fold 1 Train Loss = 0.1069, Validation Loss = 0.1161\n",
            "k-fold 1 Train Loss = 0.1062, Validation Loss = 0.1159\n",
            "k-fold 1 Train Loss = 0.1069, Validation Loss = 0.1156\n",
            "k-fold 1 Train Loss = 0.1063, Validation Loss = 0.1144\n",
            "k-fold 1 Train Loss = 0.1074, Validation Loss = 0.1150\n",
            "k-fold 1 Train Loss = 0.1063, Validation Loss = 0.1142\n",
            "k-fold 1 Train Loss = 0.1065, Validation Loss = 0.1150\n",
            "k-fold 1 Train Loss = 0.1077, Validation Loss = 0.1181\n",
            "k-fold 1 Train Loss = 0.1077, Validation Loss = 0.1189\n",
            "k-fold 1 Train Loss = 0.1160, Validation Loss = 0.1299\n",
            "k-fold 1 Train Loss = 0.1167, Validation Loss = 0.1302\n",
            "k-fold 1 Train Loss = 0.1096, Validation Loss = 0.1200\n",
            "k-fold 1 Train Loss = 0.1139, Validation Loss = 0.1205\n",
            "k-fold 1 Train Loss = 0.1139, Validation Loss = 0.1184\n",
            "k-fold 1 Train Loss = 0.1089, Validation Loss = 0.1144\n",
            "k-fold 1 Train Loss = 0.1247, Validation Loss = 0.1363\n",
            "k-fold 1 Train Loss = 0.1217, Validation Loss = 0.1297\n",
            "k-fold 1 Train Loss = 0.1122, Validation Loss = 0.1201\n",
            "k-fold 1 Train Loss = 0.1121, Validation Loss = 0.1208\n",
            "k-fold 1 Train Loss = 0.1139, Validation Loss = 0.1239\n",
            "k-fold 1 Train Loss = 0.1082, Validation Loss = 0.1173\n",
            "k-fold 1 Train Loss = 0.1150, Validation Loss = 0.1242\n",
            "k-fold 1 Train Loss = 0.1143, Validation Loss = 0.1232\n",
            "k-fold 1 Train Loss = 0.1099, Validation Loss = 0.1202\n",
            "k-fold 1 Train Loss = 0.1109, Validation Loss = 0.1223\n",
            "k-fold 1 Train Loss = 0.1104, Validation Loss = 0.1200\n",
            "k-fold 1 Train Loss = 0.1095, Validation Loss = 0.1192\n",
            "k-fold 1 Train Loss = 0.1083, Validation Loss = 0.1190\n",
            "k-fold 1 Train Loss = 0.1078, Validation Loss = 0.1186\n",
            "k-fold 1 Train Loss = 0.1076, Validation Loss = 0.1192\n",
            "k-fold 1 Train Loss = 0.1065, Validation Loss = 0.1177\n",
            "k-fold 1 Train Loss = 0.1062, Validation Loss = 0.1168\n",
            "k-fold 1 Train Loss = 0.1087, Validation Loss = 0.1181\n",
            "k-fold 1 Train Loss = 0.1083, Validation Loss = 0.1185\n",
            "k-fold 1 Train Loss = 0.1067, Validation Loss = 0.1174\n",
            "k-fold 1 Train Loss = 0.1090, Validation Loss = 0.1200\n",
            "k-fold 1 Train Loss = 0.1123, Validation Loss = 0.1233\n",
            "k-fold 1 Train Loss = 0.1091, Validation Loss = 0.1202\n",
            "k-fold 1 Train Loss = 0.1118, Validation Loss = 0.1208\n",
            "k-fold 1 Train Loss = 0.1101, Validation Loss = 0.1187\n",
            "k-fold 1 Train Loss = 0.1090, Validation Loss = 0.1183\n",
            "k-fold 1 Train Loss = 0.1084, Validation Loss = 0.1166\n",
            "k-fold 1 Train Loss = 0.1135, Validation Loss = 0.1198\n",
            "k-fold 1 Train Loss = 0.1140, Validation Loss = 0.1195\n",
            "k-fold 1 Train Loss = 0.1125, Validation Loss = 0.1178\n",
            "k-fold 1 Train Loss = 0.1093, Validation Loss = 0.1149\n",
            "k-fold 1 Train Loss = 0.1155, Validation Loss = 0.1203\n",
            "k-fold 1 Train Loss = 0.1189, Validation Loss = 0.1238\n",
            "k-fold 1 Train Loss = 0.1147, Validation Loss = 0.1203\n",
            "k-fold 1 Train Loss = 0.1096, Validation Loss = 0.1158\n",
            "k-fold 1 Train Loss = 0.1077, Validation Loss = 0.1145\n",
            "k-fold 1 Train Loss = 0.1072, Validation Loss = 0.1139\n",
            "k-fold 1 Train Loss = 0.1087, Validation Loss = 0.1155\n",
            "k-fold 1 Train Loss = 0.1072, Validation Loss = 0.1145\n",
            "k-fold 1 Train Loss = 0.1074, Validation Loss = 0.1152\n",
            "k-fold 1 Train Loss = 0.1069, Validation Loss = 0.1147\n",
            "k-fold 1 Train Loss = 0.1103, Validation Loss = 0.1171\n",
            "k-fold 1 Train Loss = 0.1100, Validation Loss = 0.1166\n",
            "k-fold 1 Train Loss = 0.1070, Validation Loss = 0.1139\n",
            "k-fold 1 Train Loss = 0.1086, Validation Loss = 0.1157\n",
            "k-fold 1 Train Loss = 0.1068, Validation Loss = 0.1145\n",
            "k-fold 1 Train Loss = 0.1069, Validation Loss = 0.1151\n",
            "k-fold 1 Train Loss = 0.1064, Validation Loss = 0.1144\n",
            "k-fold 1 Train Loss = 0.1088, Validation Loss = 0.1162\n",
            "k-fold 1 Train Loss = 0.1071, Validation Loss = 0.1154\n",
            "k-fold 1 Train Loss = 0.1088, Validation Loss = 0.1173\n",
            "k-fold 1 Train Loss = 0.1066, Validation Loss = 0.1157\n",
            "k-fold 1 Train Loss = 0.1066, Validation Loss = 0.1157\n",
            "k-fold 1 Train Loss = 0.1076, Validation Loss = 0.1174\n",
            "k-fold 1 Train Loss = 0.1277, Validation Loss = 0.1376\n",
            "k-fold 1 Train Loss = 0.1121, Validation Loss = 0.1275\n",
            "k-fold 1 Train Loss = 0.1150, Validation Loss = 0.1252\n",
            "k-fold 1 Train Loss = 0.1122, Validation Loss = 0.1206\n",
            "k-fold 1 Train Loss = 0.1075, Validation Loss = 0.1146\n",
            "k-fold 1 Train Loss = 0.1138, Validation Loss = 0.1198\n",
            "k-fold 1 Train Loss = 0.1092, Validation Loss = 0.1156\n",
            "k-fold 1 Train Loss = 0.1121, Validation Loss = 0.1187\n",
            "k-fold 1 Train Loss = 0.1152, Validation Loss = 0.1230\n",
            "k-fold 1 Train Loss = 0.1203, Validation Loss = 0.1282\n",
            "k-fold 1 Train Loss = 0.1075, Validation Loss = 0.1154\n",
            "k-fold 1 Train Loss = 0.1325, Validation Loss = 0.1413\n",
            "k-fold 1 Train Loss = 0.1111, Validation Loss = 0.1196\n",
            "k-fold 1 Train Loss = 0.1092, Validation Loss = 0.1178\n",
            "k-fold 1 Train Loss = 0.1176, Validation Loss = 0.1251\n",
            "k-fold 1 Train Loss = 0.1102, Validation Loss = 0.1173\n",
            "k-fold 1 Train Loss = 0.1121, Validation Loss = 0.1188\n",
            "k-fold 1 Train Loss = 0.1072, Validation Loss = 0.1140\n",
            "k-fold 1 Train Loss = 0.1089, Validation Loss = 0.1158\n",
            "k-fold 1 Train Loss = 0.1085, Validation Loss = 0.1152\n",
            "k-fold 1 Train Loss = 0.1077, Validation Loss = 0.1151\n",
            "k-fold 1 Train Loss = 0.1064, Validation Loss = 0.1147\n",
            "k-fold 1 Train Loss = 0.1093, Validation Loss = 0.1179\n",
            "k-fold 1 Train Loss = 0.1113, Validation Loss = 0.1200\n",
            "k-fold 1 Train Loss = 0.1067, Validation Loss = 0.1168\n",
            "k-fold 1 Train Loss = 0.1103, Validation Loss = 0.1197\n",
            "k-fold 1 Train Loss = 0.1121, Validation Loss = 0.1201\n",
            "k-fold 1 Train Loss = 0.1119, Validation Loss = 0.1182\n",
            "k-fold 1 Train Loss = 0.1099, Validation Loss = 0.1166\n",
            "k-fold 1 Train Loss = 0.1109, Validation Loss = 0.1192\n",
            "k-fold 1 Train Loss = 0.1149, Validation Loss = 0.1235\n",
            "k-fold 1 Train Loss = 0.1097, Validation Loss = 0.1170\n",
            "k-fold 1 Train Loss = 0.1170, Validation Loss = 0.1243\n",
            "k-fold 1 Train Loss = 0.1126, Validation Loss = 0.1190\n",
            "k-fold 1 Train Loss = 0.1098, Validation Loss = 0.1160\n",
            "k-fold 1 Train Loss = 0.1085, Validation Loss = 0.1156\n",
            "k-fold 1 Train Loss = 0.1074, Validation Loss = 0.1138\n",
            "k-fold 1 Train Loss = 0.1062, Validation Loss = 0.1130\n",
            "k-fold 1 Train Loss = 0.1080, Validation Loss = 0.1147\n",
            "k-fold 1 Train Loss = 0.1060, Validation Loss = 0.1135\n",
            "k-fold 1 Train Loss = 0.1059, Validation Loss = 0.1137\n",
            "k-fold 1 Train Loss = 0.1067, Validation Loss = 0.1138\n",
            "k-fold 1 Train Loss = 0.1071, Validation Loss = 0.1138\n",
            "k-fold 1 Train Loss = 0.1063, Validation Loss = 0.1126\n",
            "k-fold 1 Train Loss = 0.1100, Validation Loss = 0.1159\n",
            "k-fold 1 Train Loss = 0.1062, Validation Loss = 0.1132\n",
            "k-fold 1 Train Loss = 0.1094, Validation Loss = 0.1177\n",
            "k-fold 1 Train Loss = 0.1103, Validation Loss = 0.1179\n",
            "k-fold 1 Train Loss = 0.1068, Validation Loss = 0.1140\n",
            "k-fold 1 Train Loss = 0.1140, Validation Loss = 0.1193\n",
            "k-fold 1 Train Loss = 0.1094, Validation Loss = 0.1146\n",
            "k-fold 1 Train Loss = 0.1114, Validation Loss = 0.1168\n",
            "k-fold 1 Train Loss = 0.1064, Validation Loss = 0.1131\n",
            "k-fold 1 Train Loss = 0.1090, Validation Loss = 0.1170\n",
            "k-fold 1 Train Loss = 0.1066, Validation Loss = 0.1154\n",
            "k-fold 1 Train Loss = 0.1071, Validation Loss = 0.1146\n",
            "k-fold 1 Train Loss = 0.1083, Validation Loss = 0.1153\n",
            "k-fold 1 Train Loss = 0.1066, Validation Loss = 0.1143\n",
            "k-fold 1 Train Loss = 0.1086, Validation Loss = 0.1181\n",
            "k-fold 1 Train Loss = 0.1179, Validation Loss = 0.1281\n",
            "k-fold 1 Train Loss = 0.1070, Validation Loss = 0.1154\n",
            "k-fold 1 Train Loss = 0.1119, Validation Loss = 0.1190\n",
            "k-fold 1 Train Loss = 0.1078, Validation Loss = 0.1162\n",
            "k-fold 1 Train Loss = 0.1071, Validation Loss = 0.1164\n",
            "k-fold 1 Train Loss = 0.1062, Validation Loss = 0.1159\n",
            "k-fold 1 Train Loss = 0.1060, Validation Loss = 0.1154\n",
            "k-fold 1 Train Loss = 0.1076, Validation Loss = 0.1164\n",
            "k-fold 1 Train Loss = 0.1098, Validation Loss = 0.1176\n",
            "k-fold 1 Train Loss = 0.1096, Validation Loss = 0.1166\n",
            "k-fold 1 Train Loss = 0.1063, Validation Loss = 0.1130\n",
            "k-fold 1 Train Loss = 0.1073, Validation Loss = 0.1143\n",
            "k-fold 1 Train Loss = 0.1088, Validation Loss = 0.1168\n",
            "k-fold 1 Train Loss = 0.1078, Validation Loss = 0.1145\n",
            "k-fold 1 Train Loss = 0.1074, Validation Loss = 0.1142\n",
            "k-fold 1 Train Loss = 0.1085, Validation Loss = 0.1152\n",
            "k-fold 1 Train Loss = 0.1068, Validation Loss = 0.1132\n",
            "k-fold 1 Train Loss = 0.1079, Validation Loss = 0.1156\n",
            "k-fold 1 Train Loss = 0.1089, Validation Loss = 0.1170\n",
            "k-fold 1 Train Loss = 0.1063, Validation Loss = 0.1139\n",
            "k-fold 1 Train Loss = 0.1066, Validation Loss = 0.1133\n",
            "k-fold 1 Train Loss = 0.1064, Validation Loss = 0.1133\n",
            "k-fold 1 Train Loss = 0.1061, Validation Loss = 0.1142\n",
            "k-fold 1 Train Loss = 0.1070, Validation Loss = 0.1150\n",
            "k-fold 1 Train Loss = 0.1066, Validation Loss = 0.1151\n",
            "k-fold 1 Train Loss = 0.1065, Validation Loss = 0.1157\n",
            "k-fold 1 Train Loss = 0.1060, Validation Loss = 0.1148\n",
            "k-fold 1 Train Loss = 0.1158, Validation Loss = 0.1227\n",
            "k-fold 1 Train Loss = 0.1062, Validation Loss = 0.1135\n",
            "k-fold 1 Train Loss = 0.1149, Validation Loss = 0.1211\n",
            "k-fold 1 Train Loss = 0.1065, Validation Loss = 0.1136\n",
            "k-fold 1 Train Loss = 0.1132, Validation Loss = 0.1210\n",
            "k-fold 1 Train Loss = 0.1066, Validation Loss = 0.1149\n",
            "k-fold 1 Train Loss = 0.1087, Validation Loss = 0.1173\n",
            "k-fold 1 Train Loss = 0.1111, Validation Loss = 0.1200\n",
            "k-fold 1 Train Loss = 0.1095, Validation Loss = 0.1188\n",
            "k-fold 1 Train Loss = 0.1131, Validation Loss = 0.1223\n",
            "k-fold 1 Train Loss = 0.1068, Validation Loss = 0.1155\n",
            "k-fold 1 Train Loss = 0.1091, Validation Loss = 0.1174\n",
            "k-fold 1 Train Loss = 0.1080, Validation Loss = 0.1159\n",
            "k-fold 1 Train Loss = 0.1067, Validation Loss = 0.1144\n",
            "k-fold 1 Train Loss = 0.1082, Validation Loss = 0.1162\n",
            "k-fold 1 Train Loss = 0.1093, Validation Loss = 0.1179\n",
            "k-fold 1 Train Loss = 0.1079, Validation Loss = 0.1155\n",
            "k-fold 1 Train Loss = 0.1064, Validation Loss = 0.1138\n",
            "k-fold 1 Train Loss = 0.1069, Validation Loss = 0.1141\n",
            "k-fold 1 Train Loss = 0.1170, Validation Loss = 0.1227\n",
            "k-fold 1 Train Loss = 0.1109, Validation Loss = 0.1166\n",
            "k-fold 1 Train Loss = 0.1080, Validation Loss = 0.1140\n",
            "k-fold 1 Train Loss = 0.1075, Validation Loss = 0.1140\n",
            "k-fold 1 Train Loss = 0.1101, Validation Loss = 0.1173\n",
            "k-fold 1 Train Loss = 0.1069, Validation Loss = 0.1143\n",
            "k-fold 1 Train Loss = 0.1118, Validation Loss = 0.1193\n",
            "k-fold 1 Train Loss = 0.1071, Validation Loss = 0.1152\n",
            "k-fold 1 Train Loss = 0.1069, Validation Loss = 0.1173\n",
            "k-fold 1 Train Loss = 0.1101, Validation Loss = 0.1214\n",
            "k-fold 1 Train Loss = 0.1085, Validation Loss = 0.1192\n",
            "k-fold 1 Train Loss = 0.1076, Validation Loss = 0.1178\n",
            "k-fold 1 Train Loss = 0.1084, Validation Loss = 0.1193\n",
            "k-fold 1 Train Loss = 0.1068, Validation Loss = 0.1166\n",
            "k-fold 1 Train Loss = 0.1060, Validation Loss = 0.1157\n",
            "k-fold 1 Train Loss = 0.1076, Validation Loss = 0.1160\n",
            "k-fold 1 Train Loss = 0.1065, Validation Loss = 0.1136\n",
            "k-fold 1 Train Loss = 0.1091, Validation Loss = 0.1143\n",
            "k-fold 1 Train Loss = 0.1072, Validation Loss = 0.1133\n",
            "k-fold 1 Train Loss = 0.1095, Validation Loss = 0.1194\n",
            "k-fold 1 Train Loss = 0.1071, Validation Loss = 0.1174\n",
            "k-fold 1 Train Loss = 0.1070, Validation Loss = 0.1148\n",
            "k-fold 1 Train Loss = 0.1095, Validation Loss = 0.1160\n",
            "k-fold 1 Train Loss = 0.1067, Validation Loss = 0.1153\n",
            "k-fold 1 Train Loss = 0.1080, Validation Loss = 0.1165\n",
            "k-fold 1 Train Loss = 0.1085, Validation Loss = 0.1150\n",
            "k-fold 1 Train Loss = 0.1094, Validation Loss = 0.1163\n",
            "k-fold 1 Train Loss = 0.1076, Validation Loss = 0.1144\n",
            "k-fold 1 Train Loss = 0.1073, Validation Loss = 0.1129\n",
            "k-fold 1 Train Loss = 0.1071, Validation Loss = 0.1125\n",
            "k-fold 1 Train Loss = 0.1068, Validation Loss = 0.1128\n",
            "k-fold 1 Train Loss = 0.1120, Validation Loss = 0.1214\n",
            "k-fold 1 Train Loss = 0.1118, Validation Loss = 0.1232\n",
            "k-fold 1 Train Loss = 0.1062, Validation Loss = 0.1147\n",
            "k-fold 1 Train Loss = 0.1109, Validation Loss = 0.1177\n",
            "k-fold 1 Train Loss = 0.1108, Validation Loss = 0.1176\n",
            "k-fold 1 Train Loss = 0.1083, Validation Loss = 0.1154\n",
            "k-fold 1 Train Loss = 0.1077, Validation Loss = 0.1149\n",
            "k-fold 1 Train Loss = 0.1088, Validation Loss = 0.1167\n",
            "k-fold 1 Train Loss = 0.1068, Validation Loss = 0.1152\n",
            "k-fold 1 Train Loss = 0.1080, Validation Loss = 0.1144\n",
            "k-fold 1 Train Loss = 0.1125, Validation Loss = 0.1204\n",
            "k-fold 1 Train Loss = 0.1069, Validation Loss = 0.1151\n",
            "k-fold 1 Train Loss = 0.1079, Validation Loss = 0.1152\n",
            "k-fold 1 Train Loss = 0.1067, Validation Loss = 0.1150\n",
            "k-fold 1 Train Loss = 0.1092, Validation Loss = 0.1180\n",
            "k-fold 1 Train Loss = 0.1064, Validation Loss = 0.1145\n",
            "k-fold 1 Train Loss = 0.1100, Validation Loss = 0.1178\n",
            "k-fold 1 Train Loss = 0.1073, Validation Loss = 0.1148\n",
            "k-fold 1 Train Loss = 0.1130, Validation Loss = 0.1203\n",
            "k-fold 1 Train Loss = 0.1062, Validation Loss = 0.1151\n",
            "k-fold 1 Train Loss = 0.1082, Validation Loss = 0.1191\n",
            "k-fold 1 Train Loss = 0.1068, Validation Loss = 0.1174\n",
            "k-fold 1 Train Loss = 0.1132, Validation Loss = 0.1211\n",
            "k-fold 1 Train Loss = 0.1081, Validation Loss = 0.1181\n",
            "k-fold 1 Train Loss = 0.1063, Validation Loss = 0.1153\n",
            "k-fold 1 Train Loss = 0.1106, Validation Loss = 0.1184\n",
            "k-fold 1 Train Loss = 0.1065, Validation Loss = 0.1143\n",
            "k-fold 1 Train Loss = 0.1067, Validation Loss = 0.1148\n",
            "k-fold 1 Train Loss = 0.1071, Validation Loss = 0.1160\n",
            "k-fold 1 Train Loss = 0.1099, Validation Loss = 0.1184\n",
            "k-fold 1 Train Loss = 0.1074, Validation Loss = 0.1161\n",
            "k-fold 1 Train Loss = 0.1066, Validation Loss = 0.1157\n",
            "k-fold 1 Train Loss = 0.1132, Validation Loss = 0.1185\n",
            "k-fold 1 Train Loss = 0.1144, Validation Loss = 0.1180\n",
            "k-fold 1 Train Loss = 0.1119, Validation Loss = 0.1160\n",
            "k-fold 1 Train Loss = 0.1072, Validation Loss = 0.1129\n",
            "k-fold 1 Train Loss = 0.1064, Validation Loss = 0.1147\n",
            "k-fold 1 Train Loss = 0.1103, Validation Loss = 0.1213\n",
            "k-fold 1 Train Loss = 0.1062, Validation Loss = 0.1153\n",
            "k-fold 1 Train Loss = 0.1112, Validation Loss = 0.1179\n",
            "k-fold 1 Train Loss = 0.1104, Validation Loss = 0.1170\n",
            "k-fold 1 Train Loss = 0.1080, Validation Loss = 0.1146\n",
            "k-fold 1 Train Loss = 0.1073, Validation Loss = 0.1149\n",
            "k-fold 1 Train Loss = 0.1109, Validation Loss = 0.1191\n",
            "k-fold 1 Train Loss = 0.1106, Validation Loss = 0.1188\n",
            "k-fold 1 Train Loss = 0.1063, Validation Loss = 0.1129\n",
            "k-fold 1 Train Loss = 0.1069, Validation Loss = 0.1128\n",
            "k-fold 1 Train Loss = 0.1077, Validation Loss = 0.1139\n",
            "k-fold 1 Train Loss = 0.1071, Validation Loss = 0.1147\n",
            "k-fold 1 Train Loss = 0.1076, Validation Loss = 0.1164\n",
            "k-fold 1 Train Loss = 0.1062, Validation Loss = 0.1143\n",
            "k-fold 1 Train Loss = 0.1092, Validation Loss = 0.1162\n",
            "k-fold 1 Train Loss = 0.1062, Validation Loss = 0.1146\n",
            "k-fold 1 Train Loss = 0.1076, Validation Loss = 0.1174\n",
            "k-fold 1 Train Loss = 0.1097, Validation Loss = 0.1200\n",
            "k-fold 1 Train Loss = 0.1060, Validation Loss = 0.1154\n",
            "k-fold 1 Train Loss = 0.1175, Validation Loss = 0.1233\n",
            "k-fold 1 Train Loss = 0.1124, Validation Loss = 0.1187\n",
            "k-fold 1 Train Loss = 0.1177, Validation Loss = 0.1252\n",
            "k-fold 1 Train Loss = 0.1091, Validation Loss = 0.1223\n",
            "k-fold 1 Train Loss = 0.1085, Validation Loss = 0.1154\n",
            "k-fold 1 Train Loss = 0.1087, Validation Loss = 0.1156\n",
            "k-fold 1 Train Loss = 0.1118, Validation Loss = 0.1241\n",
            "k-fold 1 Train Loss = 0.1085, Validation Loss = 0.1252\n",
            "k-fold 1 Train Loss = 0.1088, Validation Loss = 0.1210\n",
            "k-fold 1 Train Loss = 0.1089, Validation Loss = 0.1180\n",
            "k-fold 1 Train Loss = 0.1117, Validation Loss = 0.1199\n",
            "k-fold 1 Train Loss = 0.1080, Validation Loss = 0.1168\n",
            "k-fold 1 Train Loss = 0.1113, Validation Loss = 0.1207\n",
            "k-fold 1 Train Loss = 0.1100, Validation Loss = 0.1209\n",
            "k-fold 1 Train Loss = 0.1094, Validation Loss = 0.1206\n",
            "k-fold 1 Train Loss = 0.1082, Validation Loss = 0.1157\n",
            "k-fold 1 Train Loss = 0.1105, Validation Loss = 0.1171\n",
            "k-fold 1 Train Loss = 0.1061, Validation Loss = 0.1161\n",
            "k-fold 1 Train Loss = 0.1089, Validation Loss = 0.1227\n",
            "k-fold 1 Train Loss = 0.1207, Validation Loss = 0.1361\n",
            "k-fold 1 Train Loss = 0.1063, Validation Loss = 0.1173\n",
            "k-fold 1 Train Loss = 0.1098, Validation Loss = 0.1173\n",
            "k-fold 1 Train Loss = 0.1067, Validation Loss = 0.1154\n",
            "k-fold 1 Train Loss = 0.1085, Validation Loss = 0.1179\n",
            "k-fold 1 Train Loss = 0.1062, Validation Loss = 0.1152\n",
            "k-fold 1 Train Loss = 0.1094, Validation Loss = 0.1188\n",
            "k-fold 1 Train Loss = 0.1082, Validation Loss = 0.1188\n",
            "k-fold 1 Train Loss = 0.1090, Validation Loss = 0.1199\n",
            "k-fold 1 Train Loss = 0.1090, Validation Loss = 0.1176\n",
            "k-fold 1 Train Loss = 0.1088, Validation Loss = 0.1139\n",
            "k-fold 1 Train Loss = 0.1104, Validation Loss = 0.1151\n",
            "k-fold 2 Train Loss = 0.1689, Validation Loss = 0.1580\n",
            "k-fold 2 Train Loss = 0.1596, Validation Loss = 0.1646\n",
            "k-fold 2 Train Loss = 0.1534, Validation Loss = 0.1418\n",
            "k-fold 2 Train Loss = 0.1362, Validation Loss = 0.1319\n",
            "k-fold 2 Train Loss = 0.1472, Validation Loss = 0.1545\n",
            "k-fold 2 Train Loss = 0.1352, Validation Loss = 0.1393\n",
            "k-fold 2 Train Loss = 0.1282, Validation Loss = 0.1287\n",
            "k-fold 2 Train Loss = 0.1193, Validation Loss = 0.1246\n",
            "k-fold 2 Train Loss = 0.1161, Validation Loss = 0.1208\n",
            "k-fold 2 Train Loss = 0.1133, Validation Loss = 0.1157\n",
            "k-fold 2 Train Loss = 0.1131, Validation Loss = 0.1156\n",
            "k-fold 2 Train Loss = 0.1085, Validation Loss = 0.1157\n",
            "k-fold 2 Train Loss = 0.1105, Validation Loss = 0.1193\n",
            "k-fold 2 Train Loss = 0.1091, Validation Loss = 0.1208\n",
            "k-fold 2 Train Loss = 0.1062, Validation Loss = 0.1192\n",
            "k-fold 2 Train Loss = 0.1056, Validation Loss = 0.1189\n",
            "k-fold 2 Train Loss = 0.1051, Validation Loss = 0.1196\n",
            "k-fold 2 Train Loss = 0.1052, Validation Loss = 0.1202\n",
            "k-fold 2 Train Loss = 0.1057, Validation Loss = 0.1220\n",
            "k-fold 2 Train Loss = 0.1082, Validation Loss = 0.1283\n",
            "k-fold 2 Train Loss = 0.1069, Validation Loss = 0.1244\n",
            "k-fold 2 Train Loss = 0.1234, Validation Loss = 0.1455\n",
            "k-fold 2 Train Loss = 0.1072, Validation Loss = 0.1265\n",
            "k-fold 2 Train Loss = 0.1074, Validation Loss = 0.1305\n",
            "k-fold 2 Train Loss = 0.1189, Validation Loss = 0.1413\n",
            "k-fold 2 Train Loss = 0.1068, Validation Loss = 0.1260\n",
            "k-fold 2 Train Loss = 0.1068, Validation Loss = 0.1259\n",
            "k-fold 2 Train Loss = 0.1041, Validation Loss = 0.1195\n",
            "k-fold 2 Train Loss = 0.1061, Validation Loss = 0.1186\n",
            "k-fold 2 Train Loss = 0.1052, Validation Loss = 0.1203\n",
            "k-fold 2 Train Loss = 0.1060, Validation Loss = 0.1257\n",
            "k-fold 2 Train Loss = 0.1061, Validation Loss = 0.1276\n",
            "k-fold 2 Train Loss = 0.1042, Validation Loss = 0.1270\n",
            "k-fold 2 Train Loss = 0.1055, Validation Loss = 0.1263\n",
            "k-fold 2 Train Loss = 0.1083, Validation Loss = 0.1268\n",
            "k-fold 2 Train Loss = 0.1064, Validation Loss = 0.1327\n",
            "k-fold 2 Train Loss = 0.1098, Validation Loss = 0.1320\n",
            "k-fold 2 Train Loss = 0.1041, Validation Loss = 0.1322\n",
            "k-fold 2 Train Loss = 0.1078, Validation Loss = 0.1295\n",
            "k-fold 2 Train Loss = 0.1066, Validation Loss = 0.1341\n",
            "k-fold 2 Train Loss = 0.1112, Validation Loss = 0.1302\n",
            "k-fold 2 Train Loss = 0.1191, Validation Loss = 0.1448\n",
            "k-fold 2 Train Loss = 0.1057, Validation Loss = 0.1257\n",
            "k-fold 2 Train Loss = 0.1108, Validation Loss = 0.1235\n",
            "k-fold 2 Train Loss = 0.1091, Validation Loss = 0.1320\n",
            "k-fold 2 Train Loss = 0.1084, Validation Loss = 0.1277\n",
            "k-fold 2 Train Loss = 0.1172, Validation Loss = 0.1437\n",
            "k-fold 2 Train Loss = 0.1146, Validation Loss = 0.1348\n",
            "k-fold 2 Train Loss = 0.1052, Validation Loss = 0.1323\n",
            "k-fold 2 Train Loss = 0.1126, Validation Loss = 0.1324\n",
            "k-fold 2 Train Loss = 0.1053, Validation Loss = 0.1286\n",
            "k-fold 2 Train Loss = 0.1050, Validation Loss = 0.1291\n",
            "k-fold 2 Train Loss = 0.1101, Validation Loss = 0.1293\n",
            "k-fold 2 Train Loss = 0.1051, Validation Loss = 0.1305\n",
            "k-fold 2 Train Loss = 0.1086, Validation Loss = 0.1274\n",
            "k-fold 2 Train Loss = 0.1048, Validation Loss = 0.1250\n",
            "k-fold 2 Train Loss = 0.1098, Validation Loss = 0.1312\n",
            "k-fold 2 Train Loss = 0.1079, Validation Loss = 0.1242\n",
            "k-fold 2 Train Loss = 0.1049, Validation Loss = 0.1255\n",
            "k-fold 2 Train Loss = 0.1053, Validation Loss = 0.1275\n",
            "k-fold 2 Train Loss = 0.1047, Validation Loss = 0.1277\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1280\n",
            "k-fold 2 Train Loss = 0.1161, Validation Loss = 0.1453\n",
            "k-fold 2 Train Loss = 0.1071, Validation Loss = 0.1363\n",
            "k-fold 2 Train Loss = 0.1042, Validation Loss = 0.1327\n",
            "k-fold 2 Train Loss = 0.1041, Validation Loss = 0.1313\n",
            "k-fold 2 Train Loss = 0.1056, Validation Loss = 0.1335\n",
            "k-fold 2 Train Loss = 0.1041, Validation Loss = 0.1314\n",
            "k-fold 2 Train Loss = 0.1040, Validation Loss = 0.1339\n",
            "k-fold 2 Train Loss = 0.1106, Validation Loss = 0.1378\n",
            "k-fold 2 Train Loss = 0.1044, Validation Loss = 0.1337\n",
            "k-fold 2 Train Loss = 0.1039, Validation Loss = 0.1318\n",
            "k-fold 2 Train Loss = 0.1048, Validation Loss = 0.1303\n",
            "k-fold 2 Train Loss = 0.1037, Validation Loss = 0.1267\n",
            "k-fold 2 Train Loss = 0.1093, Validation Loss = 0.1289\n",
            "k-fold 2 Train Loss = 0.1070, Validation Loss = 0.1302\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1248\n",
            "k-fold 2 Train Loss = 0.1056, Validation Loss = 0.1290\n",
            "k-fold 2 Train Loss = 0.1278, Validation Loss = 0.1559\n",
            "k-fold 2 Train Loss = 0.1147, Validation Loss = 0.1364\n",
            "k-fold 2 Train Loss = 0.1063, Validation Loss = 0.1306\n",
            "k-fold 2 Train Loss = 0.1200, Validation Loss = 0.1453\n",
            "k-fold 2 Train Loss = 0.1081, Validation Loss = 0.1252\n",
            "k-fold 2 Train Loss = 0.1069, Validation Loss = 0.1232\n",
            "k-fold 2 Train Loss = 0.1048, Validation Loss = 0.1257\n",
            "k-fold 2 Train Loss = 0.1045, Validation Loss = 0.1222\n",
            "k-fold 2 Train Loss = 0.1056, Validation Loss = 0.1241\n",
            "k-fold 2 Train Loss = 0.1064, Validation Loss = 0.1263\n",
            "k-fold 2 Train Loss = 0.1123, Validation Loss = 0.1270\n",
            "k-fold 2 Train Loss = 0.1049, Validation Loss = 0.1266\n",
            "k-fold 2 Train Loss = 0.1038, Validation Loss = 0.1257\n",
            "k-fold 2 Train Loss = 0.1080, Validation Loss = 0.1272\n",
            "k-fold 2 Train Loss = 0.1072, Validation Loss = 0.1324\n",
            "k-fold 2 Train Loss = 0.1091, Validation Loss = 0.1266\n",
            "k-fold 2 Train Loss = 0.1056, Validation Loss = 0.1274\n",
            "k-fold 2 Train Loss = 0.1047, Validation Loss = 0.1268\n",
            "k-fold 2 Train Loss = 0.1185, Validation Loss = 0.1329\n",
            "k-fold 2 Train Loss = 0.1086, Validation Loss = 0.1303\n",
            "k-fold 2 Train Loss = 0.1058, Validation Loss = 0.1282\n",
            "k-fold 2 Train Loss = 0.1087, Validation Loss = 0.1247\n",
            "k-fold 2 Train Loss = 0.1134, Validation Loss = 0.1369\n",
            "k-fold 2 Train Loss = 0.1090, Validation Loss = 0.1246\n",
            "k-fold 2 Train Loss = 0.1070, Validation Loss = 0.1290\n",
            "k-fold 2 Train Loss = 0.1066, Validation Loss = 0.1290\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1275\n",
            "k-fold 2 Train Loss = 0.1068, Validation Loss = 0.1334\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1279\n",
            "k-fold 2 Train Loss = 0.1096, Validation Loss = 0.1294\n",
            "k-fold 2 Train Loss = 0.1104, Validation Loss = 0.1371\n",
            "k-fold 2 Train Loss = 0.1069, Validation Loss = 0.1289\n",
            "k-fold 2 Train Loss = 0.1043, Validation Loss = 0.1278\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1271\n",
            "k-fold 2 Train Loss = 0.1057, Validation Loss = 0.1266\n",
            "k-fold 2 Train Loss = 0.1038, Validation Loss = 0.1259\n",
            "k-fold 2 Train Loss = 0.1075, Validation Loss = 0.1327\n",
            "k-fold 2 Train Loss = 0.1097, Validation Loss = 0.1277\n",
            "k-fold 2 Train Loss = 0.1074, Validation Loss = 0.1278\n",
            "k-fold 2 Train Loss = 0.1246, Validation Loss = 0.1521\n",
            "k-fold 2 Train Loss = 0.1242, Validation Loss = 0.1402\n",
            "k-fold 2 Train Loss = 0.1048, Validation Loss = 0.1284\n",
            "k-fold 2 Train Loss = 0.1111, Validation Loss = 0.1361\n",
            "k-fold 2 Train Loss = 0.1077, Validation Loss = 0.1248\n",
            "k-fold 2 Train Loss = 0.1060, Validation Loss = 0.1233\n",
            "k-fold 2 Train Loss = 0.1040, Validation Loss = 0.1252\n",
            "k-fold 2 Train Loss = 0.1123, Validation Loss = 0.1373\n",
            "k-fold 2 Train Loss = 0.1095, Validation Loss = 0.1275\n",
            "k-fold 2 Train Loss = 0.1038, Validation Loss = 0.1260\n",
            "k-fold 2 Train Loss = 0.1050, Validation Loss = 0.1302\n",
            "k-fold 2 Train Loss = 0.1096, Validation Loss = 0.1274\n",
            "k-fold 2 Train Loss = 0.1058, Validation Loss = 0.1260\n",
            "k-fold 2 Train Loss = 0.1045, Validation Loss = 0.1262\n",
            "k-fold 2 Train Loss = 0.1038, Validation Loss = 0.1273\n",
            "k-fold 2 Train Loss = 0.1082, Validation Loss = 0.1322\n",
            "k-fold 2 Train Loss = 0.1096, Validation Loss = 0.1287\n",
            "k-fold 2 Train Loss = 0.1041, Validation Loss = 0.1252\n",
            "k-fold 2 Train Loss = 0.1062, Validation Loss = 0.1268\n",
            "k-fold 2 Train Loss = 0.1068, Validation Loss = 0.1243\n",
            "k-fold 2 Train Loss = 0.1042, Validation Loss = 0.1251\n",
            "k-fold 2 Train Loss = 0.1046, Validation Loss = 0.1277\n",
            "k-fold 2 Train Loss = 0.1056, Validation Loss = 0.1267\n",
            "k-fold 2 Train Loss = 0.1042, Validation Loss = 0.1250\n",
            "k-fold 2 Train Loss = 0.1061, Validation Loss = 0.1261\n",
            "k-fold 2 Train Loss = 0.1047, Validation Loss = 0.1262\n",
            "k-fold 2 Train Loss = 0.1053, Validation Loss = 0.1250\n",
            "k-fold 2 Train Loss = 0.1030, Validation Loss = 0.1251\n",
            "k-fold 2 Train Loss = 0.1031, Validation Loss = 0.1269\n",
            "k-fold 2 Train Loss = 0.1030, Validation Loss = 0.1256\n",
            "k-fold 2 Train Loss = 0.1066, Validation Loss = 0.1279\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1300\n",
            "k-fold 2 Train Loss = 0.1029, Validation Loss = 0.1298\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1319\n",
            "k-fold 2 Train Loss = 0.1044, Validation Loss = 0.1354\n",
            "k-fold 2 Train Loss = 0.1038, Validation Loss = 0.1328\n",
            "k-fold 2 Train Loss = 0.1037, Validation Loss = 0.1328\n",
            "k-fold 2 Train Loss = 0.1032, Validation Loss = 0.1302\n",
            "k-fold 2 Train Loss = 0.1030, Validation Loss = 0.1294\n",
            "k-fold 2 Train Loss = 0.1050, Validation Loss = 0.1301\n",
            "k-fold 2 Train Loss = 0.1137, Validation Loss = 0.1281\n",
            "k-fold 2 Train Loss = 0.1097, Validation Loss = 0.1327\n",
            "k-fold 2 Train Loss = 0.1054, Validation Loss = 0.1233\n",
            "k-fold 2 Train Loss = 0.1100, Validation Loss = 0.1238\n",
            "k-fold 2 Train Loss = 0.1044, Validation Loss = 0.1264\n",
            "k-fold 2 Train Loss = 0.1030, Validation Loss = 0.1240\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1241\n",
            "k-fold 2 Train Loss = 0.1046, Validation Loss = 0.1271\n",
            "k-fold 2 Train Loss = 0.1114, Validation Loss = 0.1370\n",
            "k-fold 2 Train Loss = 0.1185, Validation Loss = 0.1362\n",
            "k-fold 2 Train Loss = 0.1038, Validation Loss = 0.1304\n",
            "k-fold 2 Train Loss = 0.1059, Validation Loss = 0.1354\n",
            "k-fold 2 Train Loss = 0.1136, Validation Loss = 0.1346\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1305\n",
            "k-fold 2 Train Loss = 0.1066, Validation Loss = 0.1354\n",
            "k-fold 2 Train Loss = 0.1034, Validation Loss = 0.1286\n",
            "k-fold 2 Train Loss = 0.1042, Validation Loss = 0.1310\n",
            "k-fold 2 Train Loss = 0.1032, Validation Loss = 0.1299\n",
            "k-fold 2 Train Loss = 0.1054, Validation Loss = 0.1308\n",
            "k-fold 2 Train Loss = 0.1046, Validation Loss = 0.1299\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1287\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1303\n",
            "k-fold 2 Train Loss = 0.1039, Validation Loss = 0.1291\n",
            "k-fold 2 Train Loss = 0.1028, Validation Loss = 0.1274\n",
            "k-fold 2 Train Loss = 0.1030, Validation Loss = 0.1268\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1255\n",
            "k-fold 2 Train Loss = 0.1032, Validation Loss = 0.1251\n",
            "k-fold 2 Train Loss = 0.1096, Validation Loss = 0.1326\n",
            "k-fold 2 Train Loss = 0.1035, Validation Loss = 0.1255\n",
            "k-fold 2 Train Loss = 0.1069, Validation Loss = 0.1285\n",
            "k-fold 2 Train Loss = 0.1048, Validation Loss = 0.1293\n",
            "k-fold 2 Train Loss = 0.1048, Validation Loss = 0.1240\n",
            "k-fold 2 Train Loss = 0.1055, Validation Loss = 0.1232\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1244\n",
            "k-fold 2 Train Loss = 0.1034, Validation Loss = 0.1247\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1239\n",
            "k-fold 2 Train Loss = 0.1043, Validation Loss = 0.1234\n",
            "k-fold 2 Train Loss = 0.1064, Validation Loss = 0.1283\n",
            "k-fold 2 Train Loss = 0.1037, Validation Loss = 0.1285\n",
            "k-fold 2 Train Loss = 0.1092, Validation Loss = 0.1294\n",
            "k-fold 2 Train Loss = 0.1034, Validation Loss = 0.1285\n",
            "k-fold 2 Train Loss = 0.1030, Validation Loss = 0.1270\n",
            "k-fold 2 Train Loss = 0.1034, Validation Loss = 0.1266\n",
            "k-fold 2 Train Loss = 0.1051, Validation Loss = 0.1278\n",
            "k-fold 2 Train Loss = 0.1032, Validation Loss = 0.1282\n",
            "k-fold 2 Train Loss = 0.1104, Validation Loss = 0.1387\n",
            "k-fold 2 Train Loss = 0.1123, Validation Loss = 0.1320\n",
            "k-fold 2 Train Loss = 0.1040, Validation Loss = 0.1276\n",
            "k-fold 2 Train Loss = 0.1054, Validation Loss = 0.1275\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1234\n",
            "k-fold 2 Train Loss = 0.1049, Validation Loss = 0.1279\n",
            "k-fold 2 Train Loss = 0.1105, Validation Loss = 0.1277\n",
            "k-fold 2 Train Loss = 0.1055, Validation Loss = 0.1268\n",
            "k-fold 2 Train Loss = 0.1125, Validation Loss = 0.1342\n",
            "k-fold 2 Train Loss = 0.1030, Validation Loss = 0.1241\n",
            "k-fold 2 Train Loss = 0.1108, Validation Loss = 0.1282\n",
            "k-fold 2 Train Loss = 0.1057, Validation Loss = 0.1293\n",
            "k-fold 2 Train Loss = 0.1030, Validation Loss = 0.1242\n",
            "k-fold 2 Train Loss = 0.1101, Validation Loss = 0.1272\n",
            "k-fold 2 Train Loss = 0.1031, Validation Loss = 0.1245\n",
            "k-fold 2 Train Loss = 0.1054, Validation Loss = 0.1279\n",
            "k-fold 2 Train Loss = 0.1041, Validation Loss = 0.1228\n",
            "k-fold 2 Train Loss = 0.1079, Validation Loss = 0.1226\n",
            "k-fold 2 Train Loss = 0.1038, Validation Loss = 0.1214\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1218\n",
            "k-fold 2 Train Loss = 0.1043, Validation Loss = 0.1231\n",
            "k-fold 2 Train Loss = 0.1027, Validation Loss = 0.1243\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1247\n",
            "k-fold 2 Train Loss = 0.1035, Validation Loss = 0.1251\n",
            "k-fold 2 Train Loss = 0.1030, Validation Loss = 0.1253\n",
            "k-fold 2 Train Loss = 0.1042, Validation Loss = 0.1238\n",
            "k-fold 2 Train Loss = 0.1058, Validation Loss = 0.1219\n",
            "k-fold 2 Train Loss = 0.1059, Validation Loss = 0.1214\n",
            "k-fold 2 Train Loss = 0.1047, Validation Loss = 0.1268\n",
            "k-fold 2 Train Loss = 0.1031, Validation Loss = 0.1236\n",
            "k-fold 2 Train Loss = 0.1032, Validation Loss = 0.1239\n",
            "k-fold 2 Train Loss = 0.1045, Validation Loss = 0.1275\n",
            "k-fold 2 Train Loss = 0.1035, Validation Loss = 0.1245\n",
            "k-fold 2 Train Loss = 0.1038, Validation Loss = 0.1241\n",
            "k-fold 2 Train Loss = 0.1039, Validation Loss = 0.1243\n",
            "k-fold 2 Train Loss = 0.1043, Validation Loss = 0.1238\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1265\n",
            "k-fold 2 Train Loss = 0.1034, Validation Loss = 0.1278\n",
            "k-fold 2 Train Loss = 0.1054, Validation Loss = 0.1332\n",
            "k-fold 2 Train Loss = 0.1103, Validation Loss = 0.1322\n",
            "k-fold 2 Train Loss = 0.1053, Validation Loss = 0.1292\n",
            "k-fold 2 Train Loss = 0.1093, Validation Loss = 0.1315\n",
            "k-fold 2 Train Loss = 0.1095, Validation Loss = 0.1275\n",
            "k-fold 2 Train Loss = 0.1051, Validation Loss = 0.1248\n",
            "k-fold 2 Train Loss = 0.1114, Validation Loss = 0.1341\n",
            "k-fold 2 Train Loss = 0.1042, Validation Loss = 0.1237\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1228\n",
            "k-fold 2 Train Loss = 0.1034, Validation Loss = 0.1246\n",
            "k-fold 2 Train Loss = 0.1034, Validation Loss = 0.1251\n",
            "k-fold 2 Train Loss = 0.1121, Validation Loss = 0.1260\n",
            "k-fold 2 Train Loss = 0.1054, Validation Loss = 0.1239\n",
            "k-fold 2 Train Loss = 0.1034, Validation Loss = 0.1245\n",
            "k-fold 2 Train Loss = 0.1032, Validation Loss = 0.1271\n",
            "k-fold 2 Train Loss = 0.1075, Validation Loss = 0.1348\n",
            "k-fold 2 Train Loss = 0.1054, Validation Loss = 0.1304\n",
            "k-fold 2 Train Loss = 0.1051, Validation Loss = 0.1282\n",
            "k-fold 2 Train Loss = 0.1058, Validation Loss = 0.1278\n",
            "k-fold 2 Train Loss = 0.1088, Validation Loss = 0.1276\n",
            "k-fold 2 Train Loss = 0.1035, Validation Loss = 0.1241\n",
            "k-fold 2 Train Loss = 0.1035, Validation Loss = 0.1252\n",
            "k-fold 2 Train Loss = 0.1050, Validation Loss = 0.1234\n",
            "k-fold 2 Train Loss = 0.1029, Validation Loss = 0.1244\n",
            "k-fold 2 Train Loss = 0.1030, Validation Loss = 0.1251\n",
            "k-fold 2 Train Loss = 0.1047, Validation Loss = 0.1246\n",
            "k-fold 2 Train Loss = 0.1031, Validation Loss = 0.1265\n",
            "k-fold 2 Train Loss = 0.1066, Validation Loss = 0.1328\n",
            "k-fold 2 Train Loss = 0.1087, Validation Loss = 0.1261\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1240\n",
            "k-fold 2 Train Loss = 0.1034, Validation Loss = 0.1232\n",
            "k-fold 2 Train Loss = 0.1117, Validation Loss = 0.1235\n",
            "k-fold 2 Train Loss = 0.1073, Validation Loss = 0.1263\n",
            "k-fold 2 Train Loss = 0.1062, Validation Loss = 0.1272\n",
            "k-fold 2 Train Loss = 0.1050, Validation Loss = 0.1248\n",
            "k-fold 2 Train Loss = 0.1062, Validation Loss = 0.1245\n",
            "k-fold 2 Train Loss = 0.1081, Validation Loss = 0.1304\n",
            "k-fold 2 Train Loss = 0.1050, Validation Loss = 0.1254\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1259\n",
            "k-fold 2 Train Loss = 0.1035, Validation Loss = 0.1283\n",
            "k-fold 2 Train Loss = 0.1042, Validation Loss = 0.1280\n",
            "k-fold 2 Train Loss = 0.1028, Validation Loss = 0.1264\n",
            "k-fold 2 Train Loss = 0.1032, Validation Loss = 0.1245\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1283\n",
            "k-fold 2 Train Loss = 0.1078, Validation Loss = 0.1359\n",
            "k-fold 2 Train Loss = 0.1058, Validation Loss = 0.1320\n",
            "k-fold 2 Train Loss = 0.1029, Validation Loss = 0.1291\n",
            "k-fold 2 Train Loss = 0.1059, Validation Loss = 0.1278\n",
            "k-fold 2 Train Loss = 0.1062, Validation Loss = 0.1265\n",
            "k-fold 2 Train Loss = 0.1032, Validation Loss = 0.1253\n",
            "k-fold 2 Train Loss = 0.1051, Validation Loss = 0.1310\n",
            "k-fold 2 Train Loss = 0.1076, Validation Loss = 0.1346\n",
            "k-fold 2 Train Loss = 0.1077, Validation Loss = 0.1334\n",
            "k-fold 2 Train Loss = 0.1076, Validation Loss = 0.1335\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1271\n",
            "k-fold 2 Train Loss = 0.1054, Validation Loss = 0.1276\n",
            "k-fold 2 Train Loss = 0.1050, Validation Loss = 0.1287\n",
            "k-fold 2 Train Loss = 0.1030, Validation Loss = 0.1272\n",
            "k-fold 2 Train Loss = 0.1048, Validation Loss = 0.1283\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1305\n",
            "k-fold 2 Train Loss = 0.1053, Validation Loss = 0.1347\n",
            "k-fold 2 Train Loss = 0.1029, Validation Loss = 0.1296\n",
            "k-fold 2 Train Loss = 0.1108, Validation Loss = 0.1297\n",
            "k-fold 2 Train Loss = 0.1090, Validation Loss = 0.1293\n",
            "k-fold 2 Train Loss = 0.1075, Validation Loss = 0.1321\n",
            "k-fold 2 Train Loss = 0.1155, Validation Loss = 0.1308\n",
            "k-fold 2 Train Loss = 0.1113, Validation Loss = 0.1284\n",
            "k-fold 2 Train Loss = 0.1107, Validation Loss = 0.1387\n",
            "k-fold 2 Train Loss = 0.1073, Validation Loss = 0.1351\n",
            "k-fold 2 Train Loss = 0.1081, Validation Loss = 0.1311\n",
            "k-fold 2 Train Loss = 0.1102, Validation Loss = 0.1364\n",
            "k-fold 2 Train Loss = 0.1043, Validation Loss = 0.1253\n",
            "k-fold 2 Train Loss = 0.1046, Validation Loss = 0.1242\n",
            "k-fold 2 Train Loss = 0.1103, Validation Loss = 0.1349\n",
            "k-fold 2 Train Loss = 0.1040, Validation Loss = 0.1231\n",
            "k-fold 2 Train Loss = 0.1073, Validation Loss = 0.1221\n",
            "k-fold 2 Train Loss = 0.1085, Validation Loss = 0.1264\n",
            "k-fold 2 Train Loss = 0.1046, Validation Loss = 0.1253\n",
            "k-fold 2 Train Loss = 0.1085, Validation Loss = 0.1323\n",
            "k-fold 2 Train Loss = 0.1100, Validation Loss = 0.1364\n",
            "k-fold 2 Train Loss = 0.1079, Validation Loss = 0.1383\n",
            "k-fold 2 Train Loss = 0.1057, Validation Loss = 0.1300\n",
            "k-fold 2 Train Loss = 0.1061, Validation Loss = 0.1293\n",
            "k-fold 2 Train Loss = 0.1049, Validation Loss = 0.1287\n",
            "k-fold 2 Train Loss = 0.1031, Validation Loss = 0.1303\n",
            "k-fold 2 Train Loss = 0.1071, Validation Loss = 0.1369\n",
            "k-fold 2 Train Loss = 0.1147, Validation Loss = 0.1336\n",
            "k-fold 2 Train Loss = 0.1029, Validation Loss = 0.1240\n",
            "k-fold 2 Train Loss = 0.1067, Validation Loss = 0.1247\n",
            "k-fold 2 Train Loss = 0.1035, Validation Loss = 0.1228\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1242\n",
            "k-fold 2 Train Loss = 0.1049, Validation Loss = 0.1243\n",
            "k-fold 2 Train Loss = 0.1028, Validation Loss = 0.1239\n",
            "k-fold 2 Train Loss = 0.1098, Validation Loss = 0.1367\n",
            "k-fold 2 Train Loss = 0.1053, Validation Loss = 0.1331\n",
            "k-fold 2 Train Loss = 0.1064, Validation Loss = 0.1304\n",
            "k-fold 2 Train Loss = 0.1042, Validation Loss = 0.1292\n",
            "k-fold 2 Train Loss = 0.1035, Validation Loss = 0.1289\n",
            "k-fold 2 Train Loss = 0.1073, Validation Loss = 0.1303\n",
            "k-fold 2 Train Loss = 0.1029, Validation Loss = 0.1286\n",
            "k-fold 2 Train Loss = 0.1134, Validation Loss = 0.1428\n",
            "k-fold 2 Train Loss = 0.1045, Validation Loss = 0.1244\n",
            "k-fold 2 Train Loss = 0.1092, Validation Loss = 0.1240\n",
            "k-fold 2 Train Loss = 0.1051, Validation Loss = 0.1227\n",
            "k-fold 2 Train Loss = 0.1064, Validation Loss = 0.1260\n",
            "k-fold 2 Train Loss = 0.1048, Validation Loss = 0.1231\n",
            "k-fold 2 Train Loss = 0.1042, Validation Loss = 0.1293\n",
            "k-fold 2 Train Loss = 0.1056, Validation Loss = 0.1330\n",
            "k-fold 2 Train Loss = 0.1035, Validation Loss = 0.1295\n",
            "k-fold 2 Train Loss = 0.1043, Validation Loss = 0.1275\n",
            "k-fold 2 Train Loss = 0.1066, Validation Loss = 0.1261\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1277\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1263\n",
            "k-fold 2 Train Loss = 0.1035, Validation Loss = 0.1263\n",
            "k-fold 2 Train Loss = 0.1033, Validation Loss = 0.1242\n",
            "k-fold 2 Train Loss = 0.1043, Validation Loss = 0.1250\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1260\n",
            "k-fold 2 Train Loss = 0.1124, Validation Loss = 0.1294\n",
            "k-fold 2 Train Loss = 0.1148, Validation Loss = 0.1444\n",
            "k-fold 2 Train Loss = 0.1071, Validation Loss = 0.1376\n",
            "k-fold 2 Train Loss = 0.1151, Validation Loss = 0.1335\n",
            "k-fold 2 Train Loss = 0.1088, Validation Loss = 0.1316\n",
            "k-fold 2 Train Loss = 0.1071, Validation Loss = 0.1265\n",
            "k-fold 2 Train Loss = 0.1099, Validation Loss = 0.1220\n",
            "k-fold 2 Train Loss = 0.1053, Validation Loss = 0.1203\n",
            "k-fold 2 Train Loss = 0.1066, Validation Loss = 0.1268\n",
            "k-fold 2 Train Loss = 0.1081, Validation Loss = 0.1327\n",
            "k-fold 2 Train Loss = 0.1090, Validation Loss = 0.1322\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1259\n",
            "k-fold 2 Train Loss = 0.1064, Validation Loss = 0.1247\n",
            "k-fold 2 Train Loss = 0.1066, Validation Loss = 0.1225\n",
            "k-fold 2 Train Loss = 0.1059, Validation Loss = 0.1286\n",
            "k-fold 2 Train Loss = 0.1055, Validation Loss = 0.1286\n",
            "k-fold 2 Train Loss = 0.1053, Validation Loss = 0.1212\n",
            "k-fold 2 Train Loss = 0.1069, Validation Loss = 0.1224\n",
            "k-fold 2 Train Loss = 0.1084, Validation Loss = 0.1270\n",
            "k-fold 2 Train Loss = 0.1048, Validation Loss = 0.1217\n",
            "k-fold 2 Train Loss = 0.1044, Validation Loss = 0.1227\n",
            "k-fold 2 Train Loss = 0.1081, Validation Loss = 0.1277\n",
            "k-fold 2 Train Loss = 0.1050, Validation Loss = 0.1217\n",
            "k-fold 2 Train Loss = 0.1060, Validation Loss = 0.1214\n",
            "k-fold 2 Train Loss = 0.1037, Validation Loss = 0.1235\n",
            "k-fold 2 Train Loss = 0.1042, Validation Loss = 0.1232\n",
            "k-fold 2 Train Loss = 0.1031, Validation Loss = 0.1238\n",
            "k-fold 2 Train Loss = 0.1045, Validation Loss = 0.1234\n",
            "k-fold 2 Train Loss = 0.1048, Validation Loss = 0.1236\n",
            "k-fold 2 Train Loss = 0.1036, Validation Loss = 0.1290\n",
            "k-fold 2 Train Loss = 0.1050, Validation Loss = 0.1271\n",
            "k-fold 2 Train Loss = 0.1035, Validation Loss = 0.1239\n",
            "k-fold 2 Train Loss = 0.1034, Validation Loss = 0.1246\n",
            "k-fold 2 Train Loss = 0.1042, Validation Loss = 0.1281\n",
            "k-fold 2 Train Loss = 0.1041, Validation Loss = 0.1273\n",
            "k-fold 2 Train Loss = 0.1105, Validation Loss = 0.1375\n",
            "k-fold 2 Train Loss = 0.1053, Validation Loss = 0.1328\n",
            "k-fold 2 Train Loss = 0.1101, Validation Loss = 0.1306\n",
            "k-fold 2 Train Loss = 0.1046, Validation Loss = 0.1254\n",
            "k-fold 2 Train Loss = 0.1158, Validation Loss = 0.1319\n",
            "k-fold 2 Train Loss = 0.1089, Validation Loss = 0.1233\n",
            "k-fold 2 Train Loss = 0.1068, Validation Loss = 0.1237\n",
            "k-fold 2 Train Loss = 0.1092, Validation Loss = 0.1364\n",
            "Validation Score: 0.1247, +-0.0111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=False)\n",
        "train_rmse = evaluation(trainloader)\n",
        "test_rmse = evaluation(testloader)\n",
        "\n",
        "print(\"Train RMSE: %.4f\" %train_rmse)\n",
        "print(\"Test RMSE: %.4f\" %test_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IRHAKlsXtVf",
        "outputId": "fe94b30b-f9de-40bd-cf1e-699650b9e6b9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 0.1189\n",
            "Test RMSE: 0.1389\n"
          ]
        }
      ]
    }
  ]
}